[
{
	"uri": "http://localhost:1313/hugo_aws/vi/3-blogstranslated/3.1-blog1/",
	"title": "Chiến lược để đạt thành tích xuất sắc trong cả bốn lĩnh vực thi của chứng chỉ AWS Certified Machine Learning – Specialty.",
	"tags": [],
	"description": "",
	"content": "Chiến lược để đạt thành tích xuất sắc trong cả bốn lĩnh vực thi của chứng chỉ AWS Certified Machine Learning – Specialty.\nBởi Isha Doshi và Aizhamal Nazhimidinova | vào ngày 26 tháng 8 năm 2025 | trong Amazon Machine Learning, Amazon SageMaker, AWS Training and Certification | Permalink | Share\nKhi các tổ chức nhanh chóng áp dụng các giải pháp AI, nhu cầu về các chuyên gia machine learning (ML) tiếp tục tăng. Theo báo cáo World Economic Forum Future of Jobs Report 2025, nhu cầu đối với các chuyên gia AI và ML dự kiến sẽ tăng hơn 80% vào năm 2030.\nĐể đáp ứng nhu cầu ngày càng tăng này, Amazon Web Services (AWS) cung cấp một lộ trình chứng chỉ toàn diện, giúp các chuyên gia xây dựng và xác nhận kiến thức cũng như kỹ năng ML trong việc xây dựng, huấn luyện, tinh chỉnh và triển khai các mô hình ML.\nTrong bài viết này, chúng tôi giải thích cách chuẩn bị cho chứng chỉ AWS Certified Machine Learning – Specialty, dù bạn bắt đầu từ con số 0 hay xây dựng dựa trên các chứng chỉ AWS đã có. Chúng tôi chia sẻ các điều kiện tiên quyết và hướng dẫn để giúp bạn sẵn sàng cho chứng chỉ này, cũng như thể hiện chuyên môn của bạn trong việc xây dựng các giải pháp ML với AWS.\nBốn lĩnh vực: Hướng dẫn học tập toàn diện\nThe AWS Certified Machine Learning – Specialty Exam Guide cung cấp bản thiết kế của cấu trúc chứng chỉ, mô tả chi tiết bốn lĩnh vực quan trọng và các nhiệm vụ cụ thể. Tài liệu này đóng vai trò như lộ trình chính thức cho thí sinh, phác thảo những kiến thức và kỹ năng then chốt cần có để chứng minh năng lực ML với AWS.\nBốn lĩnh vực như sau:\nData engineering (20% nội dung được tính điểm)\nExploratory data analysis (24% nội dung được tính điểm)\nModeling (36% nội dung được tính điểm)\nMachine learning implementation and operations (20% nội dung được tính điểm)\n1: Data engineering\nLĩnh vực data engineering tập trung vào các kỹ năng quan trọng trong quản lý và chuyển đổi dữ liệu cho các quy trình ML. Thí sinh phải thể hiện năng lực trong việc tạo data repositories, xác định data sources và triển khai các giải pháp ingestion bằng cách sử dụng các dịch vụ AWS. Lĩnh vực này bao gồm các kỹ năng thiết yếu về data transformation, bao gồm quy trình ETL và xử lý data pipelines cần thiết để phát triển các giải pháp machine learning hiệu quả.\nAWS Skill Builder Exam Prep Plan: AWS Certified Machine Learning – Specialty cung cấp cho bạn tài liệu học tập cho từng domain cùng với các bộ câu hỏi luyện tập chính thức. Khóa học Domain 1 Review: AWS Certified Machine Learning – Specialty mang đến hướng dẫn qua video do chuyên gia giảng dạy, liên kết các dịch vụ AWS với những mục tiêu học tập then chốt. Để học thêm, bạn có thể khám phá khóa học Data Engineer, bao quát các khái niệm Domain 1 và các dịch vụ AWS.\n2: Exploratory data analysis\nLĩnh vực exploratory data analysis tập trung vào các kỹ năng quan trọng để biến dữ liệu thô thành những insight sẵn sàng cho ML. Thí sinh phải thể hiện năng lực trong việc chuẩn bị dữ liệu, feature engineering và các kỹ thuật khám phá những pattern ẩn trong datasets. Lĩnh vực này đánh giá mức độ sẵn sàng của bạn trong việc xử lý data preprocessing, normalization và feature selection – những yếu tố thiết yếu để cải thiện hiệu suất của mô hình ML.\nKhóa học Domain 2 Review: AWS Certified Machine Learning – Specialty cung cấp hướng dẫn qua video do chuyên gia giảng dạy, liên kết các dịch vụ AWS với những mục tiêu học tập then chốt về data analysis. Khóa học Digital Classroom – Practical Data Science with Amazon SageMaker có các module và lab bao quát các kỹ thuật chuẩn bị và chuyển đổi dữ liệu.\n3: Modeling\nModeling chiếm phần lớn nhất trong chứng chỉ AWS Certified Machine Learning – Specialty, bao quát toàn bộ vòng đời modeling trên nhiều paradigms học khác nhau. Thí sinh phải thể hiện sự hiểu biết về các thuật toán ML, kỹ thuật huấn luyện mô hình và evaluation metrics. Lĩnh vực này thách thức các chuyên gia phải nắm vững những kỹ năng quan trọng trong việc lựa chọn thuật toán, huấn luyện mô hình và đánh giá hiệu suất trong nhiều kịch bản ML khác nhau.\nKhóa học Domain 3 Review: AWS Certified Machine Learning – Specialty cung cấp hướng dẫn qua video do chuyên gia giảng dạy, liên kết các dịch vụ AWS với những kỹ thuật modeling ML then chốt. Amazon SageMaker AI Getting Started là một tài nguyên bổ trợ để học thực hành.\n4: Machine learning implementation and operations\nMục 4 tập trung vào việc chuyển đổi các mô hình ML thành các giải pháp sẵn sàng cho môi trường production. Thí sinh phải thể hiện chuyên môn trong deployment strategies, quản lý vòng đời ML operations (MLOps) và model monitoring. Lĩnh vực này thách thức các chuyên gia phải nắm vững những kỹ năng then chốt trong việc triển khai các giải pháp ML, tối ưu hóa hạ tầng và đảm bảo hiệu suất mô hình hiệu quả trong môi trường production.\nKhóa học Domain 4 Review: AWS Certified Machine Learning – Specialty cung cấp hướng dẫn qua video do chuyên gia giảng dạy, liên kết các dịch vụ AWS với những MLOps và deployment strategies then chốt. Để tìm hiểu thêm về khía cạnh triển khai và vận hành của ML, hãy tham khảo khóa học Digital Classroom – MLOps Engineering on AWS.\nLộ trình đến chứng chỉ ML Specialty\nBắt đầu hành trình để hoàn thành thành công chứng chỉ AWS Certified Machine Learning – Specialty đòi hỏi một nền tảng vững chắc. Bạn nên có hiểu biết cơ bản về lập trình Python và quen thuộc với các khái niệm thống kê cơ bản cũng như các nguyên tắc ML. Trở thành một AWS ML specialist có thể theo một lộ trình học tập có cấu trúc, nhưng chứng chỉ này vẫn có thể đạt được thông qua bất kỳ con đường học tập nào giúp bạn xây dựng được chuyên môn cần thiết.\nĐối với các thí sinh muốn theo một lộ trình có cấu trúc, đây là các bước cần thực hiện:\nBước 1: AWS Certified AI Practitioner (CLF-C02)\nHoàn hảo cho người mới bắt đầu và các chuyên gia kinh doanh, chứng chỉ ở cấp độ nhập môn này tập trung vào kiến thức AI thực tiễn, các khái niệm nền tảng và giới thiệu những công cụ AI cốt lõi của AWS như Amazon SageMaker, Amazon Comprehend và Amazon Lex.\nBước 2: AWS Certified Machine Learning Engineer – Associate (MLA-C01)\nChứng chỉ ở cấp độ trung cấp này tập trung vào toàn bộ vòng đời ML và được thiết kế cho những người trực tiếp triển khai, triển khai vào production và duy trì các giải pháp ML trên AWS. Nó bao quát mọi khía cạnh từ chuẩn bị dữ liệu, huấn luyện mô hình cho đến orchestration quy trình làm việc và monitoring.\nBước 3: AWS Certified Machine Learning – Specialty (MLS-C01)\nĐối với các chuyên gia giàu kinh nghiệm với ít nhất 2 năm làm việc trong lĩnh vực ML, chứng chỉ nâng cao này xác nhận chuyên môn trong data engineering, analytics và model optimization.\nLộ trình này giúp bạn phát triển cả chiều rộng lẫn chiều sâu trong kiến thức về cloud computing, đồng thời xây dựng chuyên môn chuyên biệt trong các công nghệ ML — những kỹ năng ngày càng được săn đón khi các tổ chức tiếp tục tận dụng AI/ML để tạo lợi thế cạnh tranh.\nĐể biết thêm thông tin về việc xây dựng lộ trình sự nghiệp AI/ML của bạn, bao gồm tài nguyên chuẩn bị và định hướng chiến lược, hãy truy cập bài viết Mapping your AI/ML career journey trong AWS Training and Certification Blog.\nXây dựng từ chứng chỉ AWS Certified Machine Learning Engineer – Associate hoặc AWS Data Engineer – Associate\nDù bạn xuất phát từ nền tảng data engineering hay ML, chứng chỉ ML Specialty đều yêu cầu nắm vững toàn bộ vòng đời ML. Cả hai lộ trình đều hội tụ tại trọng tâm của ML Specialty ở các điểm sau:\nEnd-to-end ML pipelines – Hiểu cách dữ liệu được xử lý từ ingestion đến preprocessing, training, evaluation và deployment\nProduction-grade ML systems – Xây dựng các giải pháp ML có khả năng mở rộng và bảo mật cao\nAdvanced feature engineering – Tạo ra các features giúp cải thiện hiệu suất mô hình\nMLOps practices – Triển khai continuous integration và deployment (CI/CD) cho các mô hình ML\nChuẩn bị cho ML Specialty với nền tảng data engineering\nLà một AWS Data Engineer – Associate đã được chứng nhận, chuyên môn của bạn trong các dịch vụ như AWS Glue, Amazon EMR và các lựa chọn lưu trữ dữ liệu mang lại một nền tảng vững chắc cho lĩnh vực Data Engineering và Exploratory Data Analysis trong kỳ thi AWS Certified Machine Learning – Specialty. Để thu hẹp khoảng cách một cách hiệu quả, hãy tập trung mở rộng kiến thức của bạn về các kỹ thuật chuẩn bị dữ liệu chuyên biệt cho ML, bao gồm feature engineering, data cleaning cho ML workloads, và hiểu rõ cách chất lượng dữ liệu ảnh hưởng đến hiệu suất mô hình.\nHãy đặc biệt chú ý đến các khả năng data preparation của SageMaker, vốn có thể là một lĩnh vực mới so với bộ công cụ data engineering mà bạn đã quen thuộc. Domain 3 sẽ mang đến nhiều kiến thức mới nhất vì bạn sẽ cần phát triển chuyên môn trong việc lựa chọn thuật toán phù hợp, hyperparameter tuning và model evaluation metrics — những chủ đề chưa được đề cập sâu trong chứng chỉ data engineering.\nChuẩn bị cho ML Specialty với nền tảng ML engineering\nLà một AWS Certified Machine Learning Engineer – Associate, bạn đã quen thuộc với SageMaker và những kiến thức nền tảng về xây dựng, huấn luyện và triển khai các mô hình ML. Thế mạnh của bạn trong lĩnh vực modeling giúp bạn có lợi thế ngay từ đầu ở phần lớn nội dung của kỳ thi ML Specialty. Tuy nhiên, để đạt thành tích xuất sắc trong chứng chỉ ML Specialty, bạn sẽ cần đào sâu hiểu biết về các khía cạnh data engineering nhằm hỗ trợ cho những quy trình ML phức tạp.\nHãy tập trung mở rộng kiến thức của bạn về các hệ thống xử lý dữ liệu quy mô lớn như Amazon EMR và AWS Glue, những nội dung chưa được nhấn mạnh trong chứng chỉ associate. Kỳ thi ML Specialty đòi hỏi sự hiểu biết nâng cao hơn về exploratory data analysis, bao gồm các phương pháp thống kê và kỹ thuật trực quan hóa để khám phá các pattern trong các tập dữ liệu lớn. Nó yêu cầu chuyên môn trong việc tối ưu hóa mô hình cho môi trường production và triển khai các MLOps phức tạp. Bạn cũng nên củng cố kiến thức về các khía cạnh vận hành như model monitoring và triển khai ML pipelines ở quy mô lớn.\nNhững bước tiếp theo trên hành trình của bạn\nAWS cung cấp nhiều lựa chọn đào tạo được thiết kế để phù hợp với các phong cách học tập khác nhau, bao gồm Exam Prep Plan, các hands-on labs và interactive games,AWS Training Live cho các khóa đào tạo cloud do chuyên gia hướng dẫn, cùng với free online and in-person training events. Bằng cách sử dụng các tài nguyên như AWS Skill Builder, AWS Educate và các chương trình Udemy Business Leadership Academy, bạn có thể tăng tốc quá trình học tập trong lĩnh vực AI/ML phát triển nhanh chóng.\nSkill Builder cung cấp các Official Practice Question Sets miễn phí để giúp bạn hiểu định dạng của kỳ thi. Các bộ 20 câu hỏi này, do AWS phát triển, thể hiện phong cách của kỳ thi chứng chỉ.\nĐăng ký các khóa học trên Skill Builder, hoàn thành tài liệu học tập được nêu trong bài viết này và schedule your exam ngay hôm nay!\nNguồn:https://aws.amazon.com/vi/blogs/training-and-certification/strategies-for-excelling-across-all-four-exam-domains-of-the-aws-certified-machine-learning-specialty-certification/\n"
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Giới thiệu workshop serverless: tạo Lambda (Node.js/Python), nhận tham số đầu vào, tích hợp API Gateway, và triển khai API gợi ý in-app purchase. Nhấn mạnh cách giảm thời gian triển khai bằng Lambda, không cần quản lý server.\nKiến trúc tổng quát Lambda nhận event, xử lý logic, trả JSON. API Gateway làm lớp REST front door, map method → Lambda. Tùy chọn: custom domain/stage cho nhiều môi trường. Kết quả mong đợi 2 hàm Hello World (Node.js/Python) có tham số. 1 endpoint REST (GET/POST) qua API Gateway. 1 hàm logic kinh doanh (gợi ý mua hàng) trả JSON. Thời lượng và cấu trúc Phần 1: Lambda cơ bản, test trong console. Phần 2: API Gateway, mapping input, kiểm thử. Phần 3: Bài tập in-app purchase, dọn dẹp tài nguyên. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.3-lambda-basics/5.3.1-hello-node/",
	"title": "Lambda Hello World (Node.js)",
	"tags": [],
	"description": "",
	"content": "Tạo hàm Vào Lambda console → Create function → Author from scratch. Name: hello-node, Runtime: Node.js 18.x, Role: AWSLambdaBasicExecutionRole. Handler mẫu: exports.handler = async (event) =\u0026gt; { const name = (event?.queryStringParameters || {}).name || event?.name || \u0026#34;world\u0026#34;; return { statusCode: 200, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify({ message: `Hello, ${name}` }) }; }; Save và tạo test event (ví dụ {\u0026quot;name\u0026quot;:\u0026quot;Alice\u0026quot;}), xem log CloudWatch. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/4-eventparticipated/4.1-event1/",
	"title": "Sự Kiện 1 - Vietnam Cloud Day 2025",
	"tags": [],
	"description": "",
	"content": "Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders Ngày \u0026amp; Giờ: Thứ Năm, 18 tháng 9 năm 2025 | 9:00 – 17:00 VNT\nĐịa Điểm: Amazon Web Services Vietnam, Tầng 36, 2 Đường Hai Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nTrạng Thái Đăng Ký: Đã Đóng\nTổng Quan Sự Kiện Vietnam Cloud Day 2025 là một sự kiện AWS toàn diện được thiết kế cho các nhà xây dựng và lãnh đạo doanh nghiệp, với các bài phát biểu chính từ các nhà lãnh đạo chính phủ, các giám đốc điều hành AWS và các lãnh đạo ngành. Sự kiện này giới thiệu các dịch vụ mới nhất của AWS và các sáng kiến chiến lược cho AI và hiện đại hóa đám mây thông qua hai track chính: track phát sóng trực tiếp và các phiên breakout trực tiếp.\nChương Trình Track Phát Sóng Trực Tiếp Giờ (VNT) Phiên Diễn Giả 7:35 - 9:00 Đăng Ký - 9:00 - 9:20 Khai Mạc Nhà Lãnh Đạo Chính Phủ 9:20 - 9:40 Bài Phát Biểu Chính Eric Yeo, Giám Đốc Quốc Gia, Việt Nam, Campuchia, Lào \u0026amp; Myanmar, AWS 9:40 - 10:00 Bài Phát Biểu Khách Hàng 1 Tiến Sĩ Jens Lottner, CEO, Techcombank 10:00 - 10:20 Bài Phát Biểu Khách Hàng 2 Bà Trang Phùng, CEO \u0026amp; Đồng Sáng Lập, U2U Network 10:20 - 10:50 Bài Phát Biểu AWS Jaime Valles, Phó Chủ Tịch, Giám Đốc Tổng Quát Khu Vực Châu Á Thái Bình Dương và Nhật Bản, AWS 11:00 – 11:40 Thảo Luận Bảng: Điều Hướng Cuộc Cách Mạng GenAI Điều Phối Viên: Jeff Johnson, Giám Đốc Quản Lý, ASEAN, AWS Chi Tiết Thảo Luận Bảng: Điều Hướng Cuộc Cách Mạng GenAI: Chiến Lược Lãnh Đạo Cấp Cao Thảo luận này đã đi sâu vào cách các nhà lãnh đạo cấp cao có thể điều hướng hiệu quả các tổ chức của họ thông qua những tiến bộ nhanh chóng trong AI tạo sinh. Các thành viên bảng điều hành đã chia sẻ những hiểu biết và hành trình cá nhân của họ về:\nXây dựng văn hóa đổi mới Căn chỉnh các sáng kiến AI với các mục tiêu kinh doanh Quản lý những thay đổi tổ chức kèm theo tích hợp AI Các Thành Viên Bảng:\nVũ Văn, Đồng Sáng Lập \u0026amp; CEO, ELSA Corp Nguyễn Hòa Bình, Chủ Tịch, Nexttech Group Dieter Botha, CEO, TymeX Các Track Breakout (Phiên Trực Tiếp) Track 1: Tập Trung vào AI \u0026amp; Phân Tích Giờ (VNT) Phiên Diễn Giả 13:15 - 13:30 Khai Mạc \u0026amp; Giới Thiệu Track Jun Kai Loke, Chuyên Gia AI/ML SA, AWS 13:30 - 14:00 Xây Dựng Nền Tảng Dữ Liệu Thống Nhất trên AWS cho Khối Lượng Công Việc AI và Phân Tích Kiên Nguyễn, Kiến Trúc Sư Giải Pháp, AWS 14:00 - 14:30 Xây Dựng Tương Lai: Áp Dụng Gen AI và Lộ Trình trên AWS Jun Kai Loke, Chuyên Gia AI/ML SA, AWS; Tamelly Lim, Chuyên Gia Lưu Trữ SA, AWS 14:30 - 15:00 Vòng Đời Phát Triển Do AI Điều Khiển (AI-DLC) - Định Hình Tương Lai của Triển Khai Phần Mềm Bình Trần, Kiến Trúc Sư Giải Pháp Cao Cấp, AWS 15:00 - 15:30 Giải Lao Uống Trà - 15:30 - 16:00 Bảo Mật Các Ứng Dụng AI Tạo Sinh với AWS: Nguyên Tắc Cơ Bản và Thực Tiễn Tốt Nhất Taiki Dang, Kiến Trúc Sư Giải Pháp, AWS 16:00 - 16:30 Vượt Ra Ngoài Tự Động Hóa: Các Tác Nhân AI là Bộ Nhân Năng Suất Tối Ưu của Bạn Michael Armentano, Chuyên Gia GTM Toàn Cầu Chính, AWS Chi Tiết Phiên Xây Dựng Nền Tảng Dữ Liệu Thống Nhất trên AWS cho Khối Lượng Công Việc AI và Phân Tích\nPhiên này đã đi sâu vào các chiến lược và thực tiễn tốt nhất để xây dựng nền tảng dữ liệu thống nhất, có thể mở rộng trên AWS. Các tham gia viên đã học cách tận dụng các dịch vụ AWS để tạo cơ sở hạ tầng dữ liệu mạnh mẽ có thể xử lý các yêu cầu của các ứng dụng hướng dữ liệu hiện đại. Các chủ đề chính được đề cập:\nNhập dữ liệu, lưu trữ, xử lý và quản trị Quản lý và sử dụng dữ liệu hiệu quả cho phân tích nâng cao và các sáng kiến AI Xây Dựng Tương Lai: Áp Dụng Gen AI và Lộ Trình trên AWS\nAWS đã trình bày tầm nhìn toàn diện, các xu hướng mới nổi và lộ trình chiến lược cho việc áp dụng các công nghệ AI Tạo Sinh (GenAI). Cuộc thảo luận đã bao gồm các dịch vụ AWS chính và các sáng kiến được thiết kế để trao quyền cho các tổ chức trong việc tận dụng GenAI để thúc đẩy đổi mới và hiệu quả.\nVòng Đời Phát Triển Do AI Điều Khiển (AI-DLC) - Định Hình Tương Lai của Triển Khai Phần Mềm\nVòng Đời Phát Triển Do AI Điều Khiển (AI-DLC) là một cách tiếp cận biến đổi, tập trung vào AI, định hình lại tương lai của triển khai phần mềm bằng cách nhúng đầy đủ AI như một cộng tác viên trung tâm trong toàn bộ vòng đời phát triển phần mềm. Không giống như các phương pháp truyền thống nhúng AI như một trợ lý cho các quy trình do con người điều khiển hiện có, AI-DLC tích hợp thực thi do AI điều khiển với giám sát của con người và hợp tác nhóm động để:\nCải thiện đáng kể tốc độ phát triển phần mềm Nâng cao chất lượng mã Thúc đẩy đổi mới Bảo Mật Các Ứng Dụng AI Tạo Sinh với AWS: Nguyên Tắc Cơ Bản và Thực Tiễn Tốt Nhất\nPhiên này đã khám phá các thách thức bảo mật độc đáo ở mỗi lớp của ngăn xếp AI tạo sinh—cơ sở hạ tầng, mô hình và ứng dụng. Các tham gia viên đã học cách AWS tích hợp các biện pháp bảo mật tích hợp sẵn như:\nMã hóa Kiến trúc không tin tưởng Giám sát liên tục Kiểm soát truy cập chi tiết Các biện pháp này bảo vệ khối lượng công việc AI tạo sinh, đảm bảo tính bảo mật và toàn vẹn dữ liệu trong suốt vòng đời AI.\nVượt Ra Ngoài Tự Động Hóa: Các Tác Nhân AI là Bộ Nhân Năng Suất Tối Ưu của Bạn\nPhiên này đã trình bày một sự thay đổi mô hình trong đó các tác nhân AI không chỉ là công cụ, mà là những đối tác thông minh chủ động thúc đẩy kinh doanh phát triển. Các khái niệm chính bao gồm:\nCác tác nhân AI học hỏi, thích ứng và thực thi các tác vụ phức tạp một cách tự chủ Chuyển đổi hoạt động từ các quy trình thủ công sang hiệu quả chưa từng có Nhân năng suất theo cấp số nhân thông qua sức mạnh của AI Track 2: Tập Trung vào Di Chuyển Đám Mây \u0026amp; Hiện Đại Hóa Giờ (VNT) Phiên Diễn Giả 13:15 - 13:30 Khai Mạc \u0026amp; Giới Thiệu Track Hùng Nguyễn Gia, Trưởng Kiến Trúc Sư Giải Pháp, AWS 13:30 - 14:00 Hoàn Thành Di Chuyển và Hiện Đại Hóa Quy Mô Lớn với AWS Sơn Đỗ, Quản Lý Tài Khoản Kỹ Thuật, AWS; Nguyễn Văn Hải, Giám Đốc Kỹ Thuật Phần Mềm, Techcombank 14:00 - 14:30 Hiện Đại Hóa Ứng Dụng với Công Cụ Được Hỗ Trợ bởi AI Tạo Sinh Phúc Nguyễn, Kiến Trúc Sư Giải Pháp, AWS; Alex Trần, Giám Đốc AI, OCB 14:30 - 15:00 Thảo Luận Bảng: Hiện Đại Hóa Ứng Dụng - Tăng Tốc Độ Chuyển Đổi Kinh Doanh Điều Phối Viên: Hùng Nguyễn Gia, Trưởng Kiến Trúc Sư Giải Pháp, AWS 15:00 - 15:30 Giải Lao - 15:30 - 16:00 Chuyển Đổi VMware với Hiện Đại Hóa Đám Mây Do AI Điều Khiển Hùng Hoàng, Quản Lý Giải Pháp Khách Hàng, AWS 16:00 - 16:30 Bảo Mật AWS Ở Quy Mô: Từ Phát Triển đến Sản Xuất Taiki Dang, Kiến Trúc Sư Giải Pháp, AWS Chi Tiết Phiên Hoàn Thành Di Chuyển và Hiện Đại Hóa Quy Mô Lớn với AWS\nPhiên này tập trung vào những bài học quý báu từ hàng nghìn doanh nghiệp đã di chuyển và hiện đại hóa khối lượng công việc tại chỗ của họ với AWS. Các chủ đề bao gồm:\nCác mô hình tư duy được chứng minh và thực tiễn kỹ thuật tốt nhất Các con đường hiện đại hóa giúp các tổ chức hiện đại hóa trong khi di chuyển Các bộ tăng tốc di chuyển AWS và các công cụ di chuyển và hiện đại hóa mới nhất Nghiên cứu trường hợp cho thấy cách các tổ chức đã thiết lập nền tảng mạnh mẽ và lộ trình chiến lược tận dụng các khả năng đám mây AWS để đạt được các mục tiêu chuyển đổi kỹ thuật số Hiện Đại Hóa Ứng Dụng với Công Cụ Được Hỗ Trợ bởi AI Tạo Sinh\nPhiên này đã khám phá cách Amazon Q Developer biến đổi vòng đời phát triển phần mềm (SDLC) thông qua các khả năng tác nhân của nó trên:\nAWS Console IDE CLI Các nền tảng DevSecOps Các khả năng chính được trình diễn:\nCác tác nhân Q tăng tốc độ tạo mã và cải thiện chất lượng mã Tích hợp liền mạch với các quy trình công việc hiện có Tạo tự động tài liệu toàn diện và bài kiểm tra đơn vị Cải thiện khả năng bảo trì mã và độ tin cậy Hiểu các cơ sở mã phức tạp và đề xuất tối ưu hóa Tự động hóa các tác vụ thường xuyên trong vòng đời phát triển Thảo Luận Bảng: Hiện Đại Hóa Ứng Dụng - Tăng Tốc Độ Chuyển Đổi Kinh Doanh\nCác Thành Viên Bảng:\nNguyễn Minh Ngân, Chuyên Gia AI, OCB Nguyễn Mạnh Tuyền, Trưởng Ứng Dụng Dữ Liệu, LPBank Securities Vinh Nguyễn, Đồng Sáng Lập \u0026amp; CTO, Ninety Eight Chuyển Đổi VMware với Hiện Đại Hóa Đám Mây Do AI Điều Khiển\nPhiên này cho thấy cách các tổ chức Việt Nam đang tăng tốc độ áp dụng đám mây với các tài sản VMware. Các chủ đề chính:\nCách AWS Transform giúp di chuyển nhanh, an toàn và hiệu quả về chi phí Sách hướng dẫn từng bước và các mô hình nhận thức về thời gian chết Lộ trình để hiện đại hóa lên EKS, RDS và serverless sau khi hạ cánh Lý tưởng cho các nhà lãnh đạo CNTT, kiến trúc sư và các nhóm vận hành lên kế hoạch di chuyển VMware-to-AWS quy mô lớn Bảo Mật AWS Ở Quy Mô: Từ Phát Triển đến Sản Xuất\nPhiên này đã khám phá cách nâng cao tư thế bảo mật đám mây trên toàn bộ vòng đời phát triển và sản xuất. Các chủ đề được đề cập:\nCách tiếp cận bảo mật toàn diện của AWS: xác định, phòng ngừa, phát hiện, phản ứng và khắc phục Các nguyên tắc bảo mật theo thiết kế trong suốt quá trình phát triển Các khả năng phát hiện và phản ứng nâng cao Cách AI tạo sinh nâng cao phân tích bảo mật và tự động hóa hoạt động Xây dựng các kiến trúc có khả năng phục hồi phát triển theo các mối đe dọa mới nổi Tạo các môi trường đám mây an toàn hơn, có thể mở rộng Những Điểm Chính Rút Ra Hiểu biết toàn diện về chiến lược AI và hiện đại hóa đám mây của AWS Những hiểu biết thực tế về áp dụng AI ở quy mô doanh nghiệp và triển khai Thực tiễn tốt nhất cho nền tảng dữ liệu, bảo mật và hiện đại hóa ứng dụng Các nghiên cứu trường hợp thực tế và bài học từ các lãnh đạo ngành Kiến thức thực hành về các dịch vụ AWS cho GenAI, di chuyển và hiện đại hóa "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.4-api-gateway/5.4.1-create-api/",
	"title": "Tạo REST API",
	"tags": [],
	"description": "",
	"content": "Tạo API Gateway (REST) Vào API Gateway → Create API → REST API → Build. Name: serverless-workshop-api; Endpoint type: Regional → Create API. Trong Resources: chọn / → Create Resource → Path: hello → Create. (Tùy chọn) bật CORS cho resource nếu muốn gọi từ browser. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.1-week1/",
	"title": "Tuần 1 - Kiến thức Nền tảng Cloud Computing",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-09-08 đến 2025-09-12\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 1 Tuần này tập trung củng cố những khái niệm cơ bản về Cloud Computing, hạ tầng AWS và các công cụ quản trị.\nNội dung chính Giới thiệu Cloud Computing và lợi ích.Giải thích rõ ràng về Cloud Computing (Điện toán Đám mây) là gì: cung cấp các tài nguyên công nghệ thông tin (như sức mạnh tính toán, lưu trữ, cơ sở dữ liệu) theo nhu cầu, thường qua internet, với mô hình trả tiền theo mức sử dụng. AWS Global Infrastructure (Region, AZ, Edge Location). Bộ công cụ quản lý AWS (Console, CLI, SDK). Chiến lược tối ưu chi phí. AWS Well-Architected Framework. Labs thực hành Lab 01: Thiết lập tài khoản AWS \u0026amp; IAM. Lab 07: AWS Budgets \u0026amp; Cost Management. Lab 09: AWS Support Plans. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/",
	"title": "Worklog - Hành Trình Học AWS",
	"tags": [],
	"description": "",
	"content": "Worklog Tổng quan Worklog 12 tuần (5 ngày/tuần) bắt đầu 08/09/2025, tóm lược nội dung học phục vụ đánh giá: nền tảng AWS, kiến trúc, và các cập nhật GenAI/compute mới nhất từ re:Invent.\nẢnh nhanh từng tuần Tuần 1: Nền tảng đám mây, hạ tầng toàn cầu, Well-Architected Tuần 2: Mạng (VPC, SG/NACL, LB, TGW/peering, VPN/DC) Tuần 3: Tính toán (EC2/AMI/EBS, scaling, giá, EFS/FSx) Tuần 4: Lưu trữ (S3 classes, Glacier, Snow, DR/Backup) Tuần 5: Bảo mật \u0026amp; danh tính (IAM, Org, KMS, Security Hub, SSO) Tuần 6: CSDL (RDS/Aurora/Redshift, ElastiCache, DMS) Tuần 7: Serverless \u0026amp; Containers (Lambda, ECS/EKS, ECR) Tuần 8: Giám sát \u0026amp; vận hành (CloudWatch, X-Ray, CloudTrail, cost/ops) Tuần 9: Kiến trúc Transformer, attention, encoder-decoder, GPT/BERT/T5 Tuần 10: Transfer learning, QA modes, BERT \u0026amp; T5 fine-tuning Tuần 11: Lambda Managed Instances (capacity provider, mạng, scale, chi phí) Tuần 12: Thông báo re:Invent 2025 (Nova models, Bedrock, S3 Vectors, SageMaker serverless/elastic training, Graviton5, Trainium3) "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.2-prerequisite/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Tài khoản \u0026amp; quyền hạn AWS account với quyền tạo Lambda, CloudWatch Logs, API Gateway (IAM tối thiểu: AWSLambdaBasicExecutionRole). Không cần quyền EC2/VPC nâng cao cho workshop này. Công cụ Trình duyệt để thao tác AWS Console. curl/Invoke-RestMethod hoặc Postman để gọi API Gateway. Tùy chọn: editor cục bộ để soạn code Node.js/Python trước khi dán vào console. Thiết lập nhanh Chọn region gần (ví dụ us-east-1 hoặc ap-southeast-1). Tạo IAM role cho Lambda với trust policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;sts:AssumeRole\u0026#34;], \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: [\u0026#34;lambda.amazonaws.com\u0026#34;] } } ] } Gán policy AWSLambdaBasicExecutionRole cho role. Đặt CloudWatch Logs retention (ví dụ 7–14 ngày) để kiểm soát chi phí: CloudWatch → Log groups → /aws/lambda/\u0026lt;tên-hàm\u0026gt; → Actions → Edit retention. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.3-lambda-basics/5.3.2-hello-python/",
	"title": "Lambda Hello World (Python)",
	"tags": [],
	"description": "",
	"content": "Tạo hàm Vào Lambda console → Create function → Author from scratch. Name: hello-python, Runtime: Python 3.12. Handler mẫu: import json def lambda_handler(event, context): name = ( (event.get(\u0026#34;queryStringParameters\u0026#34;) or {}).get(\u0026#34;name\u0026#34;) or event.get(\u0026#34;name\u0026#34;) or \u0026#34;world\u0026#34; ) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;headers\u0026#34;: {\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;}, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;message\u0026#34;: f\u0026#34;Hello, {name}\u0026#34;}) } Save, tạo test event (ví dụ {\u0026quot;name\u0026quot;:\u0026quot;Bob\u0026quot;}), xem response và log CloudWatch. Có thể bắt lỗi body không hợp lệ và trả 400 nếu cần. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "Thư Viện Online - Nền Tảng Nội Dung Serverless Cho Nhóm Nhỏ 1. Tổng quan điều hành Dự án Thư Viện Online nhằm xây dựng một nền tảng serverless, chi phí thấp để lưu trữ và phân phối nội dung (PDF/ePub) cho một nhóm người dùng nhỏ (ban đầu ~100 người, nhóm người dùng gồm sinh viên/lab cần chia sẻ tài liệu nghiên cứu nội bộ có kiểm duyệt). Giải pháp này ưu tiên tính bảo mật, quy trình duyệt nội dung (Admin Approval), và chi phí vận hành minh bạch, tuyến tính khi mở rộng. Kiến trúc sử dụng AWS Serverless hoàn toàn (Amplify, Cognito, API Gateway, Lambda, S3, CloudFront, DynamoDB). Chi phí dự kiến cho MVP (không tính Free Tier) ≈ $9.80/tháng, đảm bảo khả năng mở rộng lên 5.000 đến 50.000 người dùng với chi phí dễ dự đoán.\n2. Vấn đề Vấn đề là gì? Tài liệu và sách bị phân tán; thiếu một hệ thống truyền tải nội dung an toàn và có kiểm soát truy cập; quy trình thêm hoặc kiểm duyệt nội dung tốn thời gian và nhiều vấn đề liên quan đến pháp lý.\nGiải pháp Xây dựng một pipeline serverless trên AWS: Người dùng tải lên qua Presigned PUT URL (tới S3 tạm); Admin phê duyệt → Lambda di chuyển file đến thư mục công khai (nhưng được bảo vệ); Người đọc truy cập qua Signed GET URL (từ CloudFront/CDN) để đảm bảo tốc độ và kiểm soát truy cập.\nLợi ích và Tỷ suất hoàn vốn Giá trị kinh doanh: Tập trung hóa nội dung; kiểm soát chất lượng qua quy trình duyệt; triển khai nhanh chóng với CI/CD. Lợi ích kỹ thuật: Chi phí vận hành thấp (≈ $9.80/tháng ở MVP, không tính Free Tier); kiến trúc Serverless có thể mở rộng quy mô lớn (scale) dễ dàng; bảo mật truy cập nội dung. 3. Kiến trúc giải pháp A. High-level B. Luồng xử lý yêu cầu Dịch vụ AWS Sử Dụng Dịch vụ Vai trò chính Hoạt động cụ thể Amplify Hosting CI/CD + FE Hosting Build \u0026amp; Deploy Next.js, quản lý domain Cognito Authentication Đăng ký/Đăng nhập, cấp JWT, refresh token API Gateway Entry point API Nhận request, xác thực JWT, route đến Lambda Lambda Business Logic Xử lý upload, duyệt, tạo signed URL, ghi metadata S3 Object Storage Lưu file gốc, file đã duyệt, được download qua Cloudfront Signed URL CloudFront CDN Phân phối nhanh nội dung, chặn direct access qua OAC DynamoDB Database Lưu metadata (tên sách, uploader, trạng thái duyệt) Route 53 DNS Trỏ domain đến Amplify Hosting, API Gateway, CloudFront CloudWatch Monitoring Lưu log Lambda, cảnh báo lỗi hoặc chi phí bất thường Tìm kiếm (Search):\nTìm kiếm đơn giản theo trường (VD: tên sách, tác giả), sử dụng DynamoDB GSIs cho các thuộc tính này và query theo GSI. Luồng xử lý yêu cầu User Upload: Presigned PUT tới S3 thư mục uploads/. Admin Approval: Lambda copy file từ uploads/ sang public/books/ khi được duyệt. Reader Security: CloudFront sử dụng Origin Access Control (OAC) để chặn truy cập trực tiếp S3 và chỉ cho phép đọc qua Signed URL (ngắn hạn) do Lambda tạo ra. Kiến trúc tìm kiếm Tìm kiếm đơn giản: Thiết kế GSI cho title và author (ví dụ: GSI1: PK=TITLE#{normalizedTitle}, SK=BOOK#{bookId}; GSI2: PK=AUTHOR#{normalizedAuthor}, SK=BOOK#{bookId}). Thêm endpoint GET /search?title=...\u0026amp;author=... để query theo GSI thay vì Scan. Phân quyền Admin Sử dụng Cognito User Groups với một nhóm Admins trong User Pool. Khi Admin đăng nhập, JWT sẽ chứa cognito:groups: [\u0026quot;Admins\u0026quot;]. Các Lambda thuộc nghiệp vụ Admin (ví dụ approveBook, takedownBook) phải kiểm tra claim này; nếu thiếu group, trả 403 Forbidden. Có thể dùng JWT Authorizer (API Gateway HTTP API) để xác thực, phần phân quyền chi tiết xử lý trong Lambda dựa trên claim. 4. Triển khai Kỹ Thuật Triển khai Thiết kế \u0026amp; IaC (Infra-as-Code): Xây dựng các stack CDK (Cognito, DDB, S3, Amplify, Lambda, API). Flow Upload \u0026amp; Duyệt: Triển khai Presigned PUT, lưu metadata (trạng thái pending), và logic Admin duyệt (copy file). Flow Đọc Sách: Triển khai endpoint Signed GET, và giao diện đọc (FE stream qua CloudFront). Vận hành (Ops): Thiết lập logs CloudWatch (retention ngắn), cảnh báo ngân sách (Budget Alerts), hardening IAM. Search: MVP: thêm GSI cho title, author và endpoint GET /search query theo GSI. Yêu cầu Kỹ Thuật Sử dụng CDK để định nghĩa toàn bộ hạ tầng. API Gateway phải là HTTP API để tối ưu chi phí. Lambda (Python) xử lý logic nghiệp vụ và tương tác DynamoDB/S3. S3 Bucket Policy phải chặn truy cập công khai và chỉ cho phép CloudFront OAC. 5. Lộ trình và các mốc tiến độ Lộ trình Dự án Nền tảng \u0026amp; Xác thực (Tuần 1-2) Mục tiêu là thiết lập hạ tầng và cho phép người dùng đăng nhập.\nTác vụ Backend (CDK/DevOps): Viết stack CDK/IaC cho Cognito (User Pool, App Client). Viết stack CDK cho DynamoDB (bảng chính, chưa cần GSI). Viết stack CDK cho S3 (Bucket uploads, public, logs) và cấu hình OAC (Origin Access Control). Triển khai API Gateway (HTTP API) và một Lambda \u0026ldquo;hello world\u0026rdquo; để kiểm thử. Tác vụ Frontend (Amplify): Cấu hình Amplify Hosting và kết nối với repo GitHub (CI/CD). Tích hợp Amplify UI / Cognito SDK cho các trang: Đăng ký, Xác thực email, Đăng nhập, Quên mật khẩu. Kết quả (Milestone): Developer có thể git push và FE tự động deploy. Người dùng có thể đăng ký/đăng nhập và nhận được JWT token. Luồng Upload \u0026amp; Duyệt (Tuần 2-3) Mục tiêu là cho phép người dùng (đã đăng nhập) tải file lên và Admin duyệt file đó.\nTác vụ Backend (CDK/Lambda): Viết Lambda createUploadUrl: Xác thực JWT (phải đăng nhập). Tạo Presigned PUT URL trỏ đến thư mục uploads/ trên S3. Ghi metadata vào DynamoDB (status: PENDING). Viết Lambda approveBook: Xác thực JWT (phải là Admin). Copy file từ uploads/ sang public/books/. Cập nhật status trong DynamoDB (status: APPROVED). Tác vụ Frontend: Xây dựng Form Upload (kéo thả, chọn file). Gọi API createUploadUrl để lấy URL. Thực hiện upload file (HTTP PUT) trực tiếp lên S3 Presigned URL. Xây dựng Giao diện Admin: Lấy danh sách sách có status PENDING. Có nút \u0026ldquo;Duyệt\u0026rdquo; (gọi API approveBook). Luồng Đọc \u0026amp; Tìm kiếm (Tuần 3-4) Mục tiêu là cho phép người dùng đọc và tìm kiếm sách đã được duyệt.\nTác vụ Backend (CDK/Lambda): Viết Lambda getReadUrl: Xác thực JWT (phải đăng nhập). Kiểm tra xem sách có status APPROVED không. Tạo Signed GET URL (ngắn hạn) qua CloudFront trỏ đến file trong public/books/. Cập nhật CDK: Thêm GSI (Global Secondary Index) cho title và author vào bảng DynamoDB. Viết Lambda searchBooks: Query DynamoDB dựa trên GSI (không dùng Scan). Tác vụ Frontend: Xây dựng Trang chủ: Hiển thị danh sách sách (từ API, không có URL). Xây dựng Thanh tìm kiếm (gọi API searchBooks). Xây dựng Giao diện Đọc sách (Reader): Khi bấm \u0026ldquo;Đọc\u0026rdquo;, gọi API getReadUrl. Dùng URL nhận được để render file (ví dụ: dùng react-pdf). Vận hành \u0026amp; Bảo mật (Tuần 5-6) Mục tiêu là \u0026ldquo;hóa cứng\u0026rdquo; hệ thống, làm cho nó an toàn và dễ giám sát.\nTác vụ Backend (CDK/Lambda): Thiết lập S3 Event Notification (cho uploads/). Viết Lambda validateMimeType: Trigger khi có file mới, đọc \u0026ldquo;magic bytes\u0026rdquo; để xác thực đúng là PDF/ePub. Nếu sai, cập nhật status: REJECTED_INVALID_TYPE. Viết Lambda takedownBook (API cho Admin) và deleteUpload (xóa file PENDING sau 72h). Tác vụ DevOps (AWS Console/CDK): Thiết lập AWS Budget Alerts (cảnh báo khi chi phí vượt $X). Thiết lập CloudWatch Alarms (ví dụ: Lambda error rate \u0026gt; 5%). Rà soát lại IAM (đảm bảo \u0026ldquo;least-privilege\u0026rdquo;), CORS (chỉ cho phép domain của Amplify). 6. Budget Estimation You can find the budget estimation on the: AWS Pricing Calculator\nDưới đây là ước tính chi phí hàng tháng nghiêm ngặt (giả định không áp dụng AWS Free Tier) tại quy mô MVP (100 người dùng).\n# AWS Service Region Monthly (USD) Notes 0 Amazon CloudFront Asia Pacific (Singapore) 0.86 10 GB data egress + 10 000 HTTPS requests 1 AWS Amplify Asia Pacific (Singapore) 1.31 100 build min + 0.5 GB storage + 2 GB served 2 Amazon API Gateway Asia Pacific (Singapore) 0.01 ~10 000 HTTP API calls/tháng 3 AWS Lambda Asia Pacific (Singapore) 0.00 128 MB RAM × 100 ms × 10 000 invokes 4 Amazon S3 (Standard) Asia Pacific (Singapore) 0.05 2 GB object storage for books/images 5 Data Transfer Asia Pacific (Singapore) 0.00 Included in CloudFront cost 6 DynamoDB (On-Demand) Asia Pacific (Singapore) 0.03 Light metadata table (0.1 GB, few reads/writes) 7 Amazon Cognito Asia Pacific (Singapore) 5.00 100 MAU, Advanced Security enabled 8 Amazon CloudWatch Asia Pacific (Singapore) 1.64 5 metrics + 0.1 GB logs/tháng 9 Amazon Route 53 Asia Pacific (Singapore) 0.90 1 Hosted Zone + DNS queries ≈ 9.80 USD / month No Free Tier applied Chi phí hạ tầng Mô hình chi phí này cho thấy sự hiệu quả của kiến trúc serverless: chi phí tập trung chủ yếu vào giá trị mang lại cho người dùng (Cognito MAU) thay vì trả tiền cho \u0026ldquo;máy chủ chờ\u0026rdquo; (idle servers).\n7. Đánh giá rủi ro Ma trận rủi ro Rủi ro Tác động Chiến lược giảm thiểu Chi phí tăng khi user đột biến Cao Giới hạn MAU, cache metadata qua CloudFront Upload lạm dụng Trung bình Giới hạn ≤ 50MB/file, xóa auto sau 72h File loại giả mạo/độc hại Trung bình S3 Event → Lambda xác thực MIME (magic bytes) Giám sát quá tải Thấp CloudWatch alert, log 14 ngày Chiến lược giảm thiểu Chi phí: Đặt AWS Budget Alerts cho CloudFront và Cognito. Nhận thức rằng Signed URL có TTL ngắn nên không cache công khai dài hạn; thay vào đó, cache metadata/API response (danh sách sách, chi tiết) trên CloudFront 3–5 phút để giảm tải API. Chỉ tạo Signed URL khi người dùng thực sự bấm đọc (on‑demand), không tạo sẵn cho cả danh sách. Tải lên: Giới hạn kích thước file ≤ 50MB cho MVP. (Có thể nâng lên 200MB khi cần, dùng multipart upload ở FE để tránh timeout.) Áp dụng Rate Limit/Throttling trên API Gateway cho các endpoint tạo Presigned URL. Thiết lập S3 Lifecycle Policy để tự động xóa file chưa duyệt ở uploads/ sau 72h. Thêm Server‑side Validation: S3 Event Notifications → Lambda đọc magic bytes (vd. thư viện file-type) để xác thực đúng PDF/ePub; nếu sai, tự động xóa và ghi trạng thái REJECTED_INVALID_TYPE vào DynamoDB. Bản quyền (DMCA): Lưu Audit Log trong DynamoDB: uploaderID, uploadTimestamp, adminApproverID, approvalTimestamp để phục vụ truy vết. Xây dựng Takedown API (chỉ Admin): cập nhật status TAKEDOWN; tùy chọn di chuyển object từ public/books/ sang quarantine/books/ (không xóa hẳn) để lưu vết. Kế hoạch ứng phó Nếu chi phí tăng vượt ngân sách, có thể tạm thời giới hạn người dùng mới thông qua hệ thống mời để kiểm soát MAU Cognito và tối ưu hóa file.\n8. Kết quả mong đợi Cải tiến kỹ thuật: Đảm bảo tốc độ truyền tải nhanh và bảo mật nội dung (CDN + Signed URL). Tạo ra một kiến trúc Serverless tiêu chuẩn trên AWS, dễ dàng mở rộng lên đến 50.000 người dùng mà không cần thay đổi kiến trúc cốt lõi. Hệ thống CI/CD hoàn toàn tự động cho cả Frontend và Backend (CDK/Amplify). Giá trị lâu dài Thiết lập một nền tảng dữ liệu tập trung và có cấu trúc cho nội dung sách. Cung cấp một tài liệu tham khảo sống về việc triển khai Serverless E2E. Khả năng tích hợp các dịch vụ phân tích (như Amazon QuickSight) hoặc AI/ML trong tương lai. Hệ thống này chứng minh khả năng xây dựng nền tảng nội dung bảo mật, tiết kiệm chi phí và mở rộng dễ dàng bằng AWS Serverless — phù hợp triển khai thực tế cho nhóm nhỏ. Rẻ\n"
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/4-eventparticipated/4.2-event2/",
	"title": "Sự Kiện 2 - AWS GenAI Builder Club",
	"tags": [],
	"description": "",
	"content": "AWS GenAI Builder Club: Vòng Đời Phát Triển Do AI Điều Khiển - Tái Tưởng Tượng Kỹ Thuật Phần Mềm Ngày \u0026amp; Giờ: Thứ Sáu, 3 tháng 10 năm 2025 | 14:00 (2:00 PM)\nĐịa Điểm: AWS Event Hall, L26 Tòa Nhà Bitexco, Thành phố Hồ Chí Minh\nGiảng Viên: Toàn Huỳnh \u0026amp; Mỹ Nguyễn\nĐiều Phối Viên: Diễm Mỹ, Đại Trương, Định Nguyễn\nTổng Quan Sự Kiện Phiên làm việc AWS GenAI Builder Club này khám phá Vòng Đời Phát Triển Do AI Điều Khiển (AI-DLC), một cách tiếp cận biến đổi đối với kỹ thuật phần mềm tích hợp AI như một cộng tác viên trung tâm trong toàn bộ quá trình phát triển. Phiên làm việc này có các bản trình diễn thực hành về Amazon Q Developer và Kiro, giới thiệu các ứng dụng thực tế của AI trong phát triển phần mềm hiện đại.\nChương Trình Giờ Phiên Giảng Viên 14:00 - 14:15 Chào Mừng - 14:15 - 15:30 Tổng Quan Vòng Đời Phát Triển Do AI Điều Khiển \u0026amp; Bản Trình Diễn Amazon Q Developer Toàn Huỳnh 15:30 - 15:45 Giải Lao - 15:45 - 16:30 Bản Trình Diễn Kiro Mỹ Nguyễn Các Khái Niệm \u0026amp; Bài Học Chính 1. Tổng Quan Vòng Đời Phát Triển Do AI Điều Khiển (AI-DLC) Triết Lý Cốt Lõi Vòng Đời Phát Triển Do AI Điều Khiển đại diện cho một sự thay đổi cơ bản trong cách phần mềm được xây dựng. Thay vì coi AI là một suy nghĩ sau hoặc công cụ hoàn thành mã đơn giản, AI-DLC nhúng AI như một đối tác thông minh trong toàn bộ quá trình phát triển.\nCác Nguyên Tắc Chính:\nBạn Kiểm Soát - AI là trợ lý của bạn, không phải người quản lý của bạn. Bạn phải duy trì quyền quyết định về hướng dự án và chi tiết triển khai.\nAI Là Cộng Tác Viên, Không Phải Thay Thế - AI nên đặt những câu hỏi quan trọng về yêu cầu, kiến trúc và mục tiêu dự án của bạn. Sự hợp tác nên là hai chiều, với bạn hướng dẫn các đề xuất của AI.\nLập Kế Hoạch Trước Triển Khai - Luôn tạo một kế hoạch toàn diện trước khi đi vào mã. AI có thể giúp tạo kế hoạch này, nhưng bạn phải xem xét, xác thực và tinh chỉnh nó.\nQuy Trình Phát Triển Bước 1: Tạo Kế Hoạch Dự Án\nXác định rõ ràng yêu cầu và phạm vi dự án Yêu cầu AI tạo kế hoạch dựa trên thông số kỹ thuật của bạn Xem xét kế hoạch một cách phê phán và yêu cầu sửa đổi Đảm bảo kế hoạch chi tiết và rõ ràng Bước 2: Chia Nhỏ Thành User Stories\nChuyển đổi kế hoạch thành user stories với tiêu chí chấp nhận rõ ràng Chia phạm vi lớn thành các đơn vị nhỏ hơn, dễ quản lý Mỗi đơn vị trở thành một dự án nhỏ có thể được giao cho các thành viên nhóm Ước tính thời gian cho mỗi đơn vị (nhưng cẩn thận với việc ước tính quá cao) Bước 3: Xác Định Ngăn Xếp Công Nghệ\nChỉ định rõ ràng các công nghệ, framework và công cụ sẽ được sử dụng Thay vì bảo AI \u0026ldquo;đừng triển khai cái này\u0026rdquo;, hãy bảo nó \u0026ldquo;triển khai theo cách này\u0026rdquo; Hướng dẫn tích cực mang lại tỷ lệ thành công cao hơn các ràng buộc tiêu cực Bước 4: Yêu Cầu \u0026amp; Thiết Kế Chi Tiết\nViết yêu cầu với độ chính xác và rõ ràng Hợp tác với AI để tạo các thông số kỹ thuật chi tiết Xác định các mô hình dữ liệu, hợp đồng API và kiến trúc hệ thống Tạo tài liệu thiết kế trước khi triển khai bắt đầu Bước 5: Triển Khai \u0026amp; Xác Minh\nTriển khai các tính năng theo kế hoạch Sử dụng cách tiếp cận phát triển mob (nhóm làm việc cùng nhau trên mã) Xác minh tất cả mã đầu ra như một nhóm Tiến hành đánh giá mã và kiểm tra chất lượng Bước 6: Kiểm Thử \u0026amp; Triển Khai\nDi chuyển qua các môi trường: Development (Dev) → Testing (QA) → User Acceptance Testing (UAT) → Production (Prod) Đảm bảo các cổng chất lượng ở mỗi giai đoạn Xác thực chức năng trước khi phát hành sản xuất Các Yếu Tố Thành Công Quan Trọng Tạo Kế Hoạch Trước - Đừng mong đợi AI xử lý mọi thứ. Luôn bắt đầu với một kế hoạch rõ ràng. Xem Xét Thường Xuyên - Liên tục xem xét các đề xuất và đầu ra của AI. Tỷ lệ lỗi cao là có thể. Bạn Là Người Quản Lý - Giá trị của bạn nằm ở xác thực mã và quản lý dự án, không phải viết từng dòng mã. Đặt Câu Hỏi Làm Rõ - Đảm bảo AI hiểu ngữ cảnh dự án của bạn bằng cách đặt những câu hỏi quan trọng về yêu cầu, kiến trúc và mục tiêu. Sử Dụng Mẫu Prompt - Tạo các prompt có cấu trúc bao gồm ngữ cảnh người dùng, user stories và yêu cầu cụ thể để nhận được phản hồi AI rõ ràng hơn. Xuất Kế Hoạch Thành Tệp - Yêu cầu AI tạo kế hoạch dưới dạng tệp bạn có thể lưu, xem xét và sửa đổi. Điều này tạo ra một tài liệu sống cho tham chiếu trong tương lai. Lịch Sự Với AI - Duy trì giao tiếp tôn trọng với các công cụ AI. Mối quan hệ tốt có thể giúp ích trong các tương tác trong tương lai (và đó chỉ là thực hành tốt!). 2. Bản Trình Diễn Amazon Q Developer Amazon Q Developer Là Gì? Amazon Q Developer là một trợ lý được hỗ trợ bởi AI biến đổi vòng đời phát triển phần mềm (SDLC) thông qua các khả năng tác nhân trên nhiều nền tảng:\nAWS Console - Giúp với cấu hình cơ sở hạ tầng và dịch vụ IDE (Integrated Development Environment) - Cung cấp các đề xuất tạo mã và tối ưu hóa CLI (Command Line Interface) - Hỗ trợ tạo lệnh và tự động hóa Các Nền Tảng DevSecOps - Tích hợp các thực tiễn bảo mật vào quy trình phát triển Các Khả Năng Chính Tạo Mã \u0026amp; Chất Lượng\nTăng tốc độ tạo mã với các đề xuất được hỗ trợ bởi AI Cải thiện chất lượng mã thông qua các khuyến nghị thông minh Duy trì tích hợp liền mạch với các quy trình công việc hiện có Hiểu các cơ sở mã phức tạp và đề xuất tối ưu hóa Tài Liệu \u0026amp; Kiểm Thử\nTự động tạo tài liệu toàn diện Tạo bài kiểm tra đơn vị với nỗ lực thủ công tối thiểu Cải thiện đáng kể khả năng bảo trì mã và độ tin cậy Giảm boilerplate và các tác vụ mã lặp lại Hợp Tác Thông Minh\nHoạt động như một cộng tác viên thông minh tận dụng các mô hình ngôn ngữ lớn Kết hợp kiến thức dịch vụ AWS sâu sắc với chuyên môn mã hóa Giúp các nhà phát triển tăng tốc độ các chu kỳ phát triển Nâng cao chất lượng mã và tăng cường tư thế bảo mật Tự Động Hóa Trên Toàn Bộ Vòng Đời Phát Triển\nTự động hóa các tác vụ thường xuyên trên toàn bộ vòng đời phát triển Giảm công việc thủ công, lặp lại Cho phép các nhà phát triển tập trung vào các tác vụ sáng tạo có giá trị cao hơn Cải thiện năng suất và hiệu quả tổng thể Thực Tiễn Tốt Nhất Khi Sử Dụng Amazon Q Developer Cung Cấp Ngữ Cảnh Rõ Ràng - Cung cấp cho Q thông tin chi tiết về dự án, kiến trúc và yêu cầu của bạn Sử Dụng Prompt Cụ Thể - Thay vì các yêu cầu mơ hồ, cung cấp các prompt cụ thể, chi tiết với các ví dụ Xem Xét Các Đề Xuất - Luôn xem xét các đề xuất của Q trước khi triển khai chúng Lặp Lại \u0026amp; Tinh Chỉnh - Nếu đề xuất đầu tiên không hoàn hảo, tinh chỉnh prompt của bạn và thử lại Tận Dụng Kiến Thức AWS - Tận dụng sự hiểu biết sâu sắc của Q về các dịch vụ AWS và thực tiễn tốt nhất 3. Bản Trình Diễn Kiro Kiro Là Gì? Kiro là một IDE tác nhân (Integrated Development Environment) được phát triển bởi Amazon Web Services lấp khoảng cách giữa việc tạo prototype nhanh được hỗ trợ bởi AI và phát triển phần mềm sẵn sàng cho sản xuất. Nó hiện đang ở giai đoạn xem trước công khai.\nTriết Lý Cốt Lõi Kiro thể hiện nguyên tắc rằng AI nên nâng cao năng suất của nhà phát triển trong khi duy trì các tiêu chuẩn chuyên nghiệp, cấu trúc rõ ràng, kiểm thử toàn diện, tài liệu và khả năng bảo trì lâu dài.\nCác Tính Năng Chính Phát Triển Theo Đặc Tả\nKhi bạn gửi yêu cầu (ví dụ: \u0026ldquo;thêm hệ thống đánh giá sản phẩm\u0026rdquo;), Kiro chuyển đổi nó thành: User stories với tiêu chí chấp nhận rõ ràng Tài liệu thiết kế Danh sách tác vụ và kế hoạch triển khai Thông số kỹ thuật có cấu trúc trước khi tạo mã Agent Hooks \u0026amp; Tự Động Hóa\nTự động kích hoạt các tác vụ dựa trên các sự kiện: Lưu tệp kích hoạt cập nhật tài liệu Commit kích hoạt tạo bài kiểm tra Các hành động cụ thể kích hoạt tối ưu hóa hiệu năng Giảm công việc thủ công, lặp lại Steering \u0026amp; Ngữ Cảnh Dự Án\nTạo các tệp steering (markdown) để mô tả: Cấu trúc và tổ chức dự án Tiêu chuẩn mã hóa và quy ước Các mô hình kiến trúc mong muốn Hướng dẫn nhóm và thực tiễn tốt nhất Giúp Kiro hiểu sâu sắc ngữ cảnh dự án của bạn Phân Tích Đa Tệp \u0026amp; Hiểu Ý Định\nPhân tích nhiều tệp đồng thời Hiểu các mục tiêu chức năng trên toàn bộ cơ sở mã Thực hiện các thay đổi phù hợp với các mục tiêu dự án tổng thể Vượt ra ngoài hoàn thành mã đơn giản Tích Hợp VS Code\nĐược xây dựng dựa trên nền tảng mã nguồn mở của VS Code Nhập cài đặt, chủ đề và tiện ích mở rộng từ VS Code Giao diện quen thuộc cho người dùng VS Code hiện có Chuyển đổi liền mạch cho các nhà phát triển Lựa Chọn Mô Hình AI Linh Hoạt\nHiện sử dụng Claude Sonnet 4 làm mặc định Chế độ \u0026ldquo;Auto\u0026rdquo; kết hợp nhiều mô hình dựa trên ngữ cảnh Cân bằng giữa chất lượng và chi phí Linh hoạt để chọn các mô hình khác nhau cho các tác vụ khác nhau Ưu Điểm Của Việc Sử Dụng Kiro Tăng Tính Minh Bạch \u0026amp; Kiểm Soát\nBắt đầu với các thông số kỹ thuật trước khi tạo mã Xem xét và xác thực các thông số kỹ thuật trước khi triển khai Giảm mã \u0026ldquo;ảo tưởng\u0026rdquo; hoặc triển khai không phù hợp Duy trì khả năng truy xuất rõ ràng từ yêu cầu đến mã Giảm Boilerplate \u0026amp; Các Tác Vụ Lặp Lại\nAgent hooks tự động hóa tạo tài liệu Tạo bài kiểm tra đơn vị tự động Cập nhật thông tin tự động Giải phóng các nhà phát triển cho công việc có giá trị cao hơn Bảo Mật \u0026amp; Quyền Riêng Tư\nHầu hết các hoạt động mã xảy ra cục bộ Dữ liệu chỉ được gửi bên ngoài với sự cho phép rõ ràng Duy trì kiểm soát thông tin nhạy cảm Khả Năng Mở Rộng \u0026amp; Linh Hoạt\nTích hợp các công cụ bên ngoài thông qua MCP (Model Context Protocol) Hỗ trợ nhiều mô hình AI Không bị ràng buộc vào một môi trường AI duy nhất Thích ứng với các quy trình làm việc nhóm khác nhau Hạn Chế \u0026amp; Cân Nhắc Trạng Thái Xem Trước - Vẫn ở giai đoạn xem trước công khai; tính ổn định và tính năng có thể thay đổi Các Dự Án Phức Tạp - Có thể gặp khó khăn trong việc hiểu ngữ cảnh sâu sắc trong các dự án rất phức tạp Cần Giám Sát - Người dùng vẫn cần giám sát và xác thực các quyết định của AI Giá Cả Trong Tương Lai - Các tầng giá dự kiến: Miễn phí: ~50 tác vụ/tháng Pro: ~1.000 tác vụ/tháng Pro+: ~3.000 tác vụ/tháng Khi Nào Nên Sử Dụng Kiro Bạn muốn một quy trình làm việc AI + lập trình duy trì tính chuyên nghiệp và cấu trúc rõ ràng Xây dựng prototype nhanh nhưng lo ngại về tính bền vững sản xuất Khám phá cách AI có thể trở thành một đồng nghiệp lập trình thực sự, không chỉ là công cụ gợi ý mã Bạn cần phát triển theo đặc tả với tài liệu và kiểm thử tự động Các Lỗi Thường Gặp Khi Sử Dụng AI Trong Phát Triển 1. Mong Đợi AI Xử Lý Mọi Thứ Vấn Đề: Nhiều nhà phát triển mong đợi AI hoàn thành toàn bộ dự án một cách tự chủ.\nGiải Pháp: Luôn tạo kế hoạch trước và xem xét thường xuyên. AI là công cụ để nâng cao năng suất, không phải thay thế phán đoán của nhà phát triển.\n2. Tỷ Lệ Lỗi Cao Vấn Đề: AI có thể mắc lỗi, đặc biệt là trong các tình huống phức tạp.\nGiải Pháp: Triển khai các chu kỳ xem xét thường xuyên. Xác thực tất cả mã do AI tạo trước khi triển khai.\n3. Thiếu Yêu Cầu Rõ Ràng Vấn Đề: Yêu cầu mơ hồ hoặc không rõ ràng dẫn đến đầu ra AI mơ hồ.\nGiải Pháp: Viết yêu cầu với độ chính xác. Hợp tác với AI để tạo các thông số kỹ thuật chi tiết trước khi triển khai.\n4. Ràng Buộc Tiêu Cực Thay Vì Hướng Dẫn Tích Cực Vấn Đề: Bảo AI \u0026ldquo;đừng làm cái này\u0026rdquo; ít hiệu quả hơn \u0026ldquo;làm cái này\u0026rdquo;.\nGiải Pháp: Sử dụng các hướng dẫn tích cực, cụ thể. Tỷ lệ thành công cao hơn đến từ hướng dẫn tích cực rõ ràng.\n5. Ngữ Cảnh Dự Án Không Đủ Vấn Đề: AI không hiểu các yêu cầu và ràng buộc độc đáo của dự án của bạn.\nGiải Pháp: Tạo các tệp steering, cung cấp ngữ cảnh chi tiết và đặt những câu hỏi quan trọng cho AI về dự án của bạn.\n6. Coi AI Là Người Quản Lý Vấn Đề: Để AI quyết định tất cả về hướng dự án và kiến trúc.\nGiải Pháp: Nhớ: Bạn là người quản lý. Giá trị của bạn nằm ở xác thực mã và giám sát dự án, không phải viết từng dòng mã.\nNhững Điểm Chính Rút Ra AI Là Trợ Lý Của Bạn - Duy trì kiểm soát các quyết định dự án và hướng triển khai\nLập Kế Hoạch Trước, Mã Sau - Luôn tạo kế hoạch toàn diện trước khi triển khai\nHợp Tác Hơn Tự Động Hóa - AI nên đặt câu hỏi và hợp tác, không chỉ thực thi lệnh\nYêu Cầu Rõ Ràng Quan Trọng - Độ chính xác trong yêu cầu dẫn đến đầu ra AI tốt hơn\nXem Xét Thường Xuyên Là Cần Thiết - Đừng mong đợi AI hoàn hảo; xem xét và xác thực liên tục\nBạn Là Người Quản Lý Mã - Giá trị của bạn nằm ở xác thực và giám sát, không phải viết từng dòng\nSử Dụng Prompt Có Cấu Trúc - Các mẫu với ngữ cảnh, user stories và yêu cầu mang lại kết quả tốt hơn\nXuất Kế Hoạch Thành Tệp - Tạo các tài liệu sống bạn có thể tham chiếu và sửa đổi\nHướng Dẫn Tích Cực Hiệu Quả Hơn - Bảo AI phải làm gì, không phải tránh làm gì\nKinh Nghiệm Quan Trọng - Sử dụng các công cụ này thực hành để hiểu khả năng và hạn chế của chúng\nCông Cụ \u0026amp; Tài Nguyên Được Đề Xuất Amazon Q Developer - Trợ lý phát triển được hỗ trợ bởi AI tích hợp với các dịch vụ AWS Kiro IDE - Môi trường phát triển theo đặc tả với hợp tác AI AWS CodeWhisperer - Công cụ tạo mã và tối ưu hóa MCP (Model Context Protocol) - Khung công tác để tích hợp các công cụ và dịch vụ bên ngoài Kết Luận Vòng Đời Phát Triển Do AI Điều Khiển đại diện cho một mô hình mới trong kỹ thuật phần mềm nơi AI và con người hợp tác như những người bình đẳng. Thành công đòi hỏi lập kế hoạch rõ ràng, xem xét thường xuyên, yêu cầu chính xác và duy trì kiểm soát của nhà phát triển đối với hướng dự án. Các công cụ như Amazon Q Developer và Kiro đang cho phép quy trình làm việc mới này, nhưng chúng hoạt động tốt nhất khi các nhà phát triển hiểu khả năng và hạn chế của chúng, và duy trì vai trò của họ là người quản lý dự án và xác thực mã.\n"
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.4-api-gateway/5.4.2-add-post/",
	"title": "Thêm phương thức POST",
	"tags": [],
	"description": "",
	"content": "Cấu hình POST /hello Chọn resource /hello → Add method → POST → Lambda Function. Chọn cùng Lambda đã dùng cho GET. Dùng Lambda proxy integration để hàm nhận đầy đủ payload; trong handler parse event.body (JSON). Triển khai \u0026amp; kiểm thử Deploy lại stage dev. Gọi thử: curl -X POST -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;name\u0026#34;:\u0026#34;api-user\u0026#34;}\u0026#39; \\ \u0026#34;\u0026lt;invoke-url\u0026gt;/hello\u0026#34; Đảm bảo response JSON trả lời đúng tên; kiểm tra log CloudWatch nếu lỗi parse. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.2-week2/",
	"title": "Tuần 2 - Dịch vụ Mạng trên AWS",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-09-15 đến 2025-09-19\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 2 Tuần này đào sâu các dịch vụ mạng của AWS, từ VPC cơ bản đến giải pháp kết nối nâng cao và cân bằng tải.\nNội dung chính Amazon VPC và Subnet. Security Group và Network ACL. Internet Gateway, NAT Gateway. VPC Peering và AWS Transit Gateway. Elastic Load Balancing (ALB, NLB, GWLB). Labs thực hành Lab 03: Amazon VPC \u0026amp; Networking Basics. Lab 10: Hybrid DNS (Route 53 Resolver). Lab 19: VPC Peering. Lab 20: AWS Transit Gateway. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/3-blogstranslated/3.2-blog2/",
	"title": "Từ lý thuyết đến thực tiễn với việc sử dụng Amazon Q Developer CLI để tạo ra các dự án AWS được tùy chỉnh",
	"tags": [],
	"description": "",
	"content": "Từ lý thuyết đến thực tiễn với việc sử dụng Amazon Q Developer CLI để tạo ra các dự án AWS được tùy chỉnh\nBởi Ifeanyi Otuonye và Favour Ezeugwa | vào ngày 26 tháng 8 năm 2025 | trong Amazon Q Developer, AWS CLI, AWS Training and Certification | Permalink | Share.\nBạn có kiến thức lý thuyết chuyên sâu về AWS, có thể thông qua việc chuẩn bị cho các kỳ thi AWS Certification, nhưng lại thấy khó khăn khi chuyển hóa kiến thức đó thành các dự án thực tiễn trong quá trình học? Bạn không đơn độc. Nhiều cloud practitioners gặp phải thách thức chung là làm thế nào để bước từ sự hiểu biết lý thuyết sang những ý tưởng triển khai thực tế. Sẽ ra sao nếu bạn có một AI-powered advisor không chỉ gợi ý các dự án phù hợp với kỹ năng và sở thích của bạn, mà còn cung cấp hướng dẫn triển khai từng bước, giúp thu hẹp khoảng cách giữa kiến thức hiện có và kinh nghiệm thực tiễn?\nTrong bài viết này, chúng tôi sẽ hướng dẫn bạn cách tạo và triển khai các dự án thực tế trên Amazon Web Services (AWS) bằng cách sử dụng Amazon Q Developer command line interface (CLI). Bằng cách kết hợp sức mạnh của AI và CLI, bạn có thể xây dựng một project generator cá nhân hóa, hiểu rõ trình độ kỹ năng của bạn và giúp bạn phát triển các giải pháp AWS thực tiễn để bổ sung vào portfolio cá nhân.\nChúng tôi thiết kế hướng dẫn này dành cho những người đã có chứng chỉ AWS hoặc những ai có kiến thức cơ bản về AWS và muốn tích lũy kinh nghiệm thực hành bằng cách xây dựng portfolio dự án của riêng mình. Điều này bao gồm những người đã được chứng nhận AWS hoặc những người muốn củng cố kỹ năng thực hành. Thông qua các prompt có chiến lược và hướng dẫn triển khai, bạn sẽ khám phá cách Amazon Q Developer CLI có thể đóng vai trò vừa là AWS project advisor vừa là trợ lý triển khai.\nHiểu về khả năng tạo dự án của Amazon Q Developer CLI\nKhác với việc tìm kiếm trong tài liệu truyền thống hoặc các kho template, Amazon Q Developer CLI hiểu ngữ cảnh và có thể tạo ra các gợi ý dự án tùy chỉnh dựa trên trình độ kỹ năng và mục tiêu của bạn. Khả năng này không chỉ dừng lại ở các gợi ý lệnh ngắn gọn mà còn giúp bạn xây dựng một lộ trình học tập thực tiễn, phát triển cùng với chuyên môn của bạn.\nKhi tương tác với Amazon Q Developer CLI, bạn đang sử dụng một công cụ hiểu rõ các best practices của AWS, các yếu tố bảo mật và các mô hình triển khai phổ biến. Sức mạnh thực sự của nó nằm ở khả năng cung cấp hướng dẫn theo ngữ cảnh, giải thích không chỉ những gì cần làm mà còn lý do tại sao các phương pháp nhất định được khuyến nghị.\nCác điều kiện tiên quyết\nTrước khi bắt đầu, bạn cần có các điều kiện tiên quyết sau:\nMột tài khoản AWS với các quyền phù hợp trong AWS Identity and Access Management (IAM), bao gồm AmazonS3FullAccess, quyền IAM role và quyền Amazon Q Developer CLI (bedrock:InvokeModel và bedrock:InvokeModelWithResponseStream).\nMôi trường cục bộ của bạn nên được cài đặt cả AWS Command Line Interface (AWS CLI) và Amazon Q Developer CLI, đồng thời được cấu hình để xác thực với tài khoản AWS của bạn. Để biết thông tin về cách cài đặt, hãy tham khảo Installing or updating to the latest version of the AWS CLI và Installing Amazon Q for command line. Để làm quen với các công cụ này, hãy theo dõi hướng dẫn AWS CLI Getting Started và Amazon Q Developer CLI trong AWS Skill Builder. Việc sử dụng Amazon Q Developer tuân theo mô hình trả phí theo mức sử dụng (pay-as-you-go), vì vậy hãy theo dõi mức sử dụng của bạn qua AWS Management Console để quản lý chi phí hiệu quả. Đồng thời, tham khảo tài liệu Amazon Q Developer pricing để biết chi tiết chi phí cụ thể.\nSau khi thiết lập thành công, bạn sẽ thấy giao diện chat của Amazon Q Developer CLI.\nTạo các prompt dự án hiệu quả\nChất lượng các gợi ý dự án phụ thuộc đáng kể vào cách bạn giao tiếp với Amazon Q Developer CLI. Thông qua việc tạo prompt cẩn thận, bạn có thể khai thác các ý tưởng dự án cụ thể, phù hợp với khả năng hiện tại và mục tiêu học tập của mình. Ví dụ, nếu bạn là một AWS Certified Cloud Practitioner, Amazon Q Developer CLI có thể gợi ý các dự án xây dựng dựa trên các khái niệm của chứng chỉ này đồng thời mang đến kinh nghiệm triển khai thực hành.\nDưới đây là một ví dụ prompt thực tiễn cho giao diện chat của Amazon Q Developer CLI:\nYou are my AWS project advisor with expertise in helping beginners\nimplement practical AWS solutions. I am an AWS Certified Cloud Practitioner looking to build my first hands-on projects. Please suggest three beginner-friendly projects using Amazon S3 that:\n1. Build upon Cloud Practitioner knowledge\n2. Follow AWS best practices and Well-Architected Framework\n3. Are free-tier friendly\n4. Have clear learning outcomes\n5. Can be completed within a few hours\nFor each project suggestion, please include:\n- The main AWS services involved\n- Key learning objectives\n- Estimated time to complete\n- Potential real-world applications\nKhi bạn gửi prompt tới Amazon Q Developer CLI, phản hồi sẽ cung cấp các gợi ý được cấu trúc cẩn thận, phù hợp với cả kiến thức chứng chỉ của bạn lẫn nhu cầu học tập thực hành. Từ những gợi ý này, chúng ta sẽ tập trung vào dự án được đề xuất là triển khai một static website hosting, một điểm khởi đầu lý tưởng kết hợp các khái niệm AWS cơ bản với kết quả thực tế.\nSau khi gửi prompt ví dụ tới Amazon Q Developer CLI, nó sẽ cung cấp các gợi ý được cấu trúc cẩn thận, phù hợp với cả kiến thức chứng chỉ của bạn và nhu cầu học tập thực hành. Từ những gợi ý này, chúng ta sẽ tập trung vào ý tưởng dự án là triển khai một static website với Amazon CloudFront distribution. Dự án thân thiện với người mới này kết hợp ba dịch vụ AWS chính: Amazon Simple Storage Service (Amazon S3) để hosting, Amazon CloudFront để phân phối nội dung toàn cầu, và tùy chọn Amazon Route 53 để quản lý domain. Với thời gian hoàn thành ước tính 2–3 giờ, đây là điểm khởi đầu lý tưởng kết hợp các khái niệm cơ bản của AWS với kết quả thực tế.\nTừ ý tưởng dự án đến các bước triển khai\nViệc chuyển từ ý tưởng sang triển khai đòi hỏi các định nghĩa hạ tầng rõ ràng. Amazon Q Developer CLI nổi bật trong việc tạo ra các lệnh triển khai chính xác đồng thời vẫn thân thiện với người mới. Hãy yêu cầu Amazon Q Developer CLI cung cấp các bước triển khai bằng prompt sau:\nAs my AWS project advisor, help me implement a simple version of the static website hosting solution using Amazon S3 from project 1.\nFor each step:\n1. Provide the exact AWS CLI commands needed\n2. Explain the purpose and importance of each command\n3. Include necessary security considerations\n4. Highlight best practices\n5. Mention potential gotchas or common mistakes to avoid\nPhản hồi được tạo ra, bao gồm các bước và lệnh CLI, thể hiện cách Amazon Q Developer CLI có thể trở thành công cụ học tập, minh họa cách cấu hình S3 bucket đúng, thiết lập website hosting và các quyền cần thiết. Nó hướng dẫn bạn từng lệnh, giải thích cách các thành phần phối hợp với nhau để tạo ra một giải pháp static website hosting vừa bảo mật vừa hoạt động hiệu quả.\nTriển khai và thực hành trực tiếp\nMặc dù Amazon Q Developer CLI có thể tự động thực thi các lệnh và quản lý quy trình triển khai, việc học thực sự đến từ việc bạn tự thực hiện các bước. Hãy triển khai bước đầu tiên từ phản hồi được tạo ra bằng cách tạo một S3 bucket sử dụng AWS CLI, như minh họa trong hình trước.\nĐể tạo S3 bucket của bạn, mở một cửa sổ terminal mới. Nhập lệnh sau từ bước được tạo bởi Amazon Q Developer CLI để tạo S3 bucket, thay thế my-name trong tên bucket bằng tên của bạn để đảm bảo tính duy nhất:\naws s3 mb s3://my-portfilio-site-2025-my-name --region us-east-1\nSau khi tạo S3 bucket, tiếp tục thực hiện từng bước triển khai còn lại, từ việc bật static website hosting đến bước cuối cùng là lấy URL endpoint của website tĩnh. Hãy đảm bảo bạn hiểu mục đích của từng lệnh. Khi gặp khó khăn, Amazon Q Developer CLI sẽ hỗ trợ bạn; nếu gặp vấn đề hoặc cần làm rõ, hãy yêu cầu Amazon Q Developer CLI trợ giúp. Nó sẽ cung cấp hướng dẫn khắc phục, giải thích nguyên nhân tiềm ẩn và các giải pháp. Quá trình gặp và giải quyết vấn đề này sẽ là một phần quan trọng trong hành trình học tập của bạn. Sau khi hoàn thành tất cả các bước còn lại để triển khai static website và lấy URL endpoint, hãy sao chép và dán vào trình duyệt để xem website trực tiếp của bạn. Nếu mọi việc diễn ra suôn sẻ, xin chúc mừng bạn đã triển khai thành công dự án AWS đầu tiên với Amazon Q Developer CLI!\nHạ tầng dưới dạng mã với Amazon Q Developer CLI\nBây giờ, sau khi bạn đã triển khai thủ công static website, bạn có thể khám phá các tính năng mạnh mẽ khác của Amazon Q Developer CLI, chẳng hạn như tạo hạ tầng dưới dạng mã (Infrastructure as Code – IaC).\nHãy yêu cầu Amazon Q Developer CLI tạo một AWS Cloud Development Kit (AWS CDK) stack đại diện cho việc triển khai của bạn và cung cấp giải thích về các thành phần của nó:\nCreate a CDK TypeScript stack for the S3 static website we just built manually.\nAfter generating the code, please explain:\n- The main components of the CDK stack\n- How each component relates to our manual implementation steps\n- Any best practices or optimizations included in the generated code\n- How this CDK implementation enhances our project\u0026rsquo;s maintainability and scalability\nAmazon Q Developer CLI sẽ tạo ra một triển khai CDK hoàn chỉnh và cung cấp giải thích chi tiết, biến các bước thủ công của bạn thành hạ tầng dưới dạng mã với bối cảnh bổ sung. Bạn có thể sử dụng cách tiếp cận này để quản lý phiên bản hạ tầng, đảm bảo triển khai nhất quán giữa các môi trường và củng cố hiểu biết về các dịch vụ AWS cũng như các nguyên tắc IaC.\nBuilding on your success\nSau khi triển khai thành công static website trên Amazon S3, bạn có thể cân nhắc cải thiện hiệu suất và bảo mật của nó. Một cải tiến tự nhiên là thêm Amazon CloudFront, một content delivery network (CDN) giúp phân phối nội dung website nhanh hơn tới người dùng trên toàn cầu đồng thời tăng cường bảo mật. Để tìm hiểu cách bắt đầu với CloudFront, hãy truy cập Amazon CloudFront Getting Started trong AWS Skill Builder.\nAmazon Q Developer CLI có thể hướng dẫn bạn trong quá trình cải tiến này. Sử dụng ngôn ngữ tự nhiên để yêu cầu nó giải thích cách thêm CloudFront vào static website Amazon S3 hiện có của bạn, và nó sẽ cung cấp các bước và lệnh cần thiết. Cải tiến này sẽ nâng cao hiệu suất website của bạn và giới thiệu các khái niệm quan trọng như CDNs, edge locations và cache behaviors.\nDọn dẹp tài nguyên của bạn\nSau khi hoàn thành dự án static website, việc xóa những tài nguyên không còn cần thiết là rất quan trọng. Thực hành này giúp bạn tránh phát sinh chi phí không cần thiết và củng cố nguyên tắc cost optimization trong Well-Architected Framework. Để xóa các tài nguyên được tạo trong hướng dẫn này, bạn có thể yêu cầu Amazon Q Developer CLI hướng dẫn quá trình dọn dẹp bằng prompt sau:\nProvide the commands in the correct order to help me clean up all the AWS resources we created for the static website project, including the S3 bucket, its contents etc.\nAmazon Q Developer CLI sẽ cung cấp cho bạn các lệnh AWS CLI phù hợp để xóa tài nguyên một cách an toàn. Thông thường, việc này bao gồm xóa tất cả các object trong S3 bucket trước, sau đó xóa chính bucket. Nếu bạn đã nâng cấp dự án với CloudFront, bạn cũng cần vô hiệu hóa và xóa distribution. Thói quen này sẽ rất hữu ích khi bạn tiến tới các dự án phức tạp hơn với nhiều dịch vụ AWS và chi phí tiềm năng cao hơn.\nTích hợp với các tài nguyên đào tạo AWS\nMặc dù Amazon Q Developer CLI cung cấp hướng dẫn dự án mạnh mẽ, nó hoạt động hiệu quả nhất khi kết hợp với các tài nguyên học tập toàn diện mà AWS cung cấp. Kinh nghiệm thực hành từ dự án này bổ trợ cho các khóa đào tạo có sẵn trên AWS Skill Builder. Ví dụ, khóa Introduction to Amazon S3 cung cấp bối cảnh sâu hơn về khả năng static website hosting, trong khi khóa “AWS Command Line Interface Basics” giúp bạn hiểu rõ các lệnh CLI hơn.\nHãy xây dựng một nhịp học kết hợp giữa công việc dự án với Amazon Q Developer CLI và các khóa đào tạo AWS có cấu trúc. Bắt đầu với các khái niệm cơ bản trên AWS Skill Builder, triển khai chúng bằng hướng dẫn của Amazon Q Developer CLI, sau đó phản ánh lại những gì bạn đã xây dựng. Cách tiếp cận này giúp củng cố kiến thức đồng thời tạo ra các sản phẩm thực tế cho portfolio của bạn.\nKết luận\nHành trình từ kiến thức AWS Certification đến triển khai thực tế không nhất thiết phải khó khăn. Bằng cách sử dụng Amazon Q Developer CLI như một cố vấn dự án và hướng dẫn triển khai, bạn đã khám phá ra cách tiếp cận đơn giản để xây dựng các giải pháp AWS dựa trên dự án. Phương pháp này sẽ giúp bạn tạo các dự án xứng đáng đưa vào portfolio và đào sâu hiểu biết về các dịch vụ AWS thông qua kinh nghiệm thực hành. Hãy nhớ rằng, mọi chuyên gia AWS đều bắt đầu với những dự án đơn giản như static website mà bạn vừa triển khai theo hướng dẫn trong bài viết này. Khi bạn tự tin hơn, hãy sử dụng Amazon Q Developer CLI để khám phá các kiến trúc và triển khai phức tạp hơn. Kinh nghiệm thực tiễn từ các dự án này, kết hợp với các tài nguyên đào tạo AWS, sẽ tạo nền tảng vững chắc cho hành trình học tập của bạn.\nTài nguyên bổ sung\nĐể tiếp tục hành trình học tập, hãy khám phá các tài nguyên AWS sau:\nAWS Command Line Interface Basics\nAmazon Q Developer CLI User Guide\nAmazon S3 Getting Started\nAmazon CloudFront Getting Started\nChúng tôi khuyến khích bạn bắt đầu với dự án static website được trình bày trong bài viết này. Khi đã quen, hãy nâng cấp dự án với CloudFront để tìm hiểu về CDNs. Chia sẻ các triển khai của bạn, đặt câu hỏi trong các diễn đàn cộng đồng AWS và tiếp tục xây dựng. Dự án AWS tiếp theo của bạn chỉ cách một prompt.\nVề các tác giả\nIfeanyi Otuonye\nIfeanyi Otuonye là Technical Account Manager và là chuyên gia AWS Certified 10 lần. Với vai trò cố vấn chiến lược, ông giúp khách hàng đạt được mục tiêu kinh doanh với các dịch vụ AWS Cloud. Là một người đam mê giáo dục và truyền cảm hứng, ông phát triển các nội dung và tài nguyên giúp việc học cloud trở nên dễ tiếp cận, trao quyền cho các chuyên gia phát triển kiến thức, ảnh hưởng và tác động. Bạn có thể kết nối với ông trên LinkedIn.\nFavour Ezeugwa\nFavour Ezeugwa là Solutions Architect tại Amazon Web Services (AWS), nơi cô giúp khách hàng thiết kế các kiến trúc cloud có khả năng mở rộng, bảo mật và tối ưu chi phí. Với nền\ntảng hệ thống thông tin máy tính và đam mê về generative AI và bảo mật cloud, Favour đã dẫn dắt các dự án quan trọng bao gồm phát triển trợ lý AI và ứng dụng serverless. Cô là người ủng hộ học tập thực hành, mentorship và sử dụng công nghệ để tạo ra thay đổi ý nghĩa.\nNguồn:https://aws.amazon.com/vi/blogs/training-and-certification/from-theory-to-practice-using-amazon-q-developer-cli-to-generate-tailored-aws-projects/\n"
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.4-api-gateway/5.4.3-test-api/",
	"title": "Kiểm Thử API Gateway",
	"tags": [],
	"description": "",
	"content": "Kiểm thử GET Dùng curl:\ncurl \u0026quot;\u0026lt;invoke-url\u0026gt;/\u0026quot; Kỳ vọng: HTTP 200, body {\u0026quot;message\u0026quot;:\u0026quot;Hello, tester\u0026quot;}. Nếu sai tên hoặc lỗi 5xx, xem log CloudWatch. PS C:\\Users\\Nhan\\Documents\\hugo_aws\u0026gt; curl \u0026#34;https://tyuyo8aqwd.execute-api.us-east-1.amazonaws.com/dev/hello\u0026#34; StatusCode : 200 StatusDescription : OK Content : {\u0026#34;message\u0026#34;: \u0026#34;hello\u0026#34;} RawContent : HTTP/1.1 200 OK x-amzn-RequestId: 07039249-41a2-4024-8939-5b8d676f46e7 x-amz-apigw-id: VLGW2G0loAMEm5Q= X-Amzn-Trace-Id: Root=1-693450f8-a03e8d0a53d 6c1ca901a1626;Parent=5c411597312990c1;Sample d=0;L... Forms : {} Headers : {[x-amzn-RequestId, 07039249-41a2-4024-8939-5b8d676f46e7], [x-amz-apigw-id, VLGW2G0loAMEm5Q=], [X-Amzn-Trace-Id, Root=1-693450f8-a03e8d0a53 d6c1ca901a1626;Parent=5c411597312990c1;Sampl ed=0;Lineage=1:b8101292:0], [Connection, Keep-Alive]...} Images : {} InputFields : {} Links : {} ParsedHtml : System.__ComObject RawContentLength : 20 Kiểm thử POST Dùng curl/Postman:\ncurl -X POST -H \u0026quot;Content-Type: application/json\u0026quot; -d '{\u0026quot;name\u0026quot;:\u0026quot;tester\u0026quot;}' \u0026quot;\u0026lt;invoke-url\u0026gt;/hello\u0026quot; Kỳ vọng: JSON trả lời đúng tên, mã 200. Nếu Lambda không parse body, kiểm tra event.body và JSON.parse. C:\\Users\\Nhan\u0026gt;curl -X POST -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{}\u0026#39; \u0026#34;https://tyuyo8aqwd.execute-api.us-east-1.amazonaws.com/dev/hello\u0026#34; {\u0026#34;message\u0026#34;: \u0026#34;hello\u0026#34;} Xử lý lỗi (tùy chọn) Thiết lập trả 400 khi thiếu name hoặc body không phải JSON. Ghi log input để dễ debug: console.log(event) hoặc log các field cần thiết. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.3-lambda-basics/",
	"title": "Lambda cơ bản",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tạo và kiểm thử Lambda Hello World (Node.js/Python), truyền tham số đầu vào, và tinh chỉnh cấu hình (memory, timeout, log).\nCác bước chính Tạo hàm Node.js\nRuntime: Node.js 18.x (ví dụ).\nHandler mẫu trả JSON { message: \u0026quot;hello\u0026quot; }.\nTest event với tham số name, log kết quả ở CloudWatch. Tạo hàm Python\nRuntime: Python 3.12 (ví dụ). Handler đọc event[\u0026quot;name\u0026quot;] và trả lời tùy biến. Tham số hóa \u0026amp; lỗi thường gặp\nĐọc event (query/body sẽ được API Gateway gắn thêm ở bước sau). Bắt lỗi key thiếu, trả mã trạng thái phù hợp. Tối ưu nhẹ\nChỉnh Memory và Timeout để cân bằng chi phí/hiệu năng. Đặt CloudWatch retention. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "Phần này liệt kê và giới thiệu các blog bạn đã dịch:\nBlog 1 - Chiến lược để đạt thành tích xuất sắc trong cả bốn lĩnh vực thi của chứng chỉ AWS Certified Machine Learning – Specialty Blog 2 - Từ lý thuyết đến thực tiễn với việc sử dụng Amazon Q Developer CLI để tạo ra các dự án AWS được tùy chỉnh Blog 3 - Triển khai các chiến lược áp dụng AWS Graviton nâng cao trên các AWS Regions "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/3-blogstranslated/3.3-blog3/",
	"title": "Triển khai các chiến lược áp dụng AWS Graviton nâng cao trên các AWS Regions",
	"tags": [],
	"description": "",
	"content": "Triển khai các chiến lược áp dụng AWS Graviton nâng cao trên các AWS Regions\nBởi Matt Howard | vào ngày 26 tháng 8 năm 2025 | trong Advanced (300), Amazon EC2, Best Practices, Graviton | Permalink | Share\nTriển khai các chiến lược áp dụng AWS Graviton nâng cao trên các AWS Regions bởi Matt Howard vào ngày 26 AUG 2025 trong Advanced (300), Amazon EC2, Best Practices, Graviton Permalink Share\nAWS Graviton Processors có thể mang lại tiết kiệm chi phí, cải thiện hiệu suất và giảm lượng khí thải carbon khi sử dụng các Amazon Elastic Compute Cloud (Amazon EC2) instances. Khi mở rộng triển khai Graviton trên nhiều AWS Regions, việc lập kế hoạch cẩn thận sẽ giúp bạn cân nhắc các yếu tố về khả năng sẵn có của loại instance theo từng vùng và tối ưu hóa năng lực. Bài viết này hướng dẫn cách triển khai các chiến lược cấu hình nâng cao cho các Graviton-enabled EC2 Auto Scaling groups trên nhiều Regions, giúp bạn tối đa hóa khả năng sẵn có của instance, giảm chi phí và duy trì hiệu suất ứng dụng nhất quán ngay cả ở các Regions có hạn chế về loại instance Graviton.\nChiến lược linh hoạt loại instance\nMột trong những chiến lược hiệu quả nhất để tối đa hóa khả năng sẵn có của Graviton là linh hoạt sử dụng nhiều loại instance và family khác nhau. Instance families (như m7g, c7g, và r7g) nhóm các instance tương tự với các kích thước khác nhau, mỗi kích thước cung cấp tỉ lệ vCPU và bộ nhớ tăng dần. Khi cấu hình EC2 Auto Scaling groups, hãy cố gắng sử dụng ít nhất 10 loại instance thay vì giới hạn chỉ một hoặc hai loại cụ thể. EC2 Auto Scaling hỗ trợ sự linh hoạt này thông qua mixed instances group, cho phép bạn chỉ định nhiều loại instance trong cùng một group. Hãy xem ví dụ snippet AWS CloudFormation cho EC2 Auto Scaling group [MixedInstancesPolicy](https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-autoscaling-autoscalinggroup.html cfn-autoscaling-autoscalinggroup-mixedinstancespolicy), trong đó chỉ định hai loại Graviton instance thuộc hai family khác nhau:\n\u0026ldquo;MixedInstancesPolicy\u0026rdquo;: {\n\u0026ldquo;Overrides\u0026rdquo;: [\n{ \u0026quot;InstanceType\u0026quot;: \u0026quot;m7g.large\u0026quot; }, { \u0026quot;InstanceType\u0026quot;: \u0026quot;c7g.xlarge\u0026quot; } ]\n}\nViệc giới hạn lựa chọn này làm giảm đáng kể khả năng truy cập vào các capacity pools sẵn có. Giả sử workload này cần tối thiểu 2 vCPU và 8 GiB bộ nhớ, bạn có thể thêm tám loại Graviton instance bổ sung sau: m6g.large, m8g.large, m6gd.large, m7gd.large, m8gd.large, c6g.xlarge, c6gd.xlarge và c8g.xlarge. Điều này giúp bạn đáp ứng khuyến nghị về việc linh hoạt sử dụng 10 loại instance. Mặc dù một số loại instance này có mức giá khác nhau, bạn có thể quản lý các tác động về chi phí này thông qua các chiến lược phân bổ được thảo luận sau trong bài viết.\nĐể xác định hiệu quả tất cả các loại Graviton instance tương thích cho workload của bạn, bạn có thể sử dụng GetInstanceTypesFromInstanceRequirements. Cách tiếp cận này loại bỏ nỗ lực thủ công trong việc nghiên cứu và chọn từng loại instance riêng lẻ.\naws ec2 get-instance-types-from-instance-requirements \\\n--architecture-types arm64 \\\n--virtualization-types hvm \\\n--instance-requirements \u0026lsquo;{\u0026ldquo;VCpuCount\u0026rdquo;: {\u0026ldquo;Min\u0026rdquo;: 2,\u0026ldquo;Max\u0026rdquo;:8}, \u0026ldquo;MemoryMiB\u0026rdquo;: {\u0026ldquo;Min\u0026rdquo;: 8000}, \u0026ldquo;InstanceGenerations\u0026rdquo;:[\u0026ldquo;current\u0026rdquo;]}\u0026rsquo; \\\n--region us-east-1\nLệnh ví dụ này trả về hàng chục loại Graviton instance tương thích thuộc nhiều family khác nhau (c7g, c7gd, c7gn, m7g, m7gd, v.v.), từ đó mở rộng các tùy chọn capacity của bạn. Mixed instance policy của một EC2 Auto Scaling group có thể cho phép [tối đa 40 loại phiên bản](https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_LaunchTemplateOverrides.html API_LaunchTemplateOverrides_Contents), nhờ đó bạn có nhiều không gian linh hoạt hơn nữa.\nSau khi mở rộng lựa chọn loại instance, bạn cần cấu hình cách EC2 Auto Scaling chọn giữa các loại instance sẵn có. Thuộc tính [OnDemandAllocationStrategy](https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-properties-autoscaling-autoscalinggroup-instancesdistribution.html cfn-autoscaling-autoscalinggroup-instancesdistribution-ondemandallocationstrategy) trong CloudFormation kiểm soát hành vi này, cung cấp hai cách tiếp cận: “lowest-price” và “prioritized”. Với chiến lược “lowest-price”, EC2 Auto Scaling sẽ khởi chạy các instance từ capacity pool có giá thấp nhất sẵn có:\n\u0026ldquo;OnDemandAllocationStrategy\u0026rdquo;: \u0026ldquo;lowest-price\u0026rdquo;\nChiến lược này giúp quản lý chi phí khi bạn đã bao gồm nhiều loại instance khác nhau. Ngay cả khi đã mở rộng tính linh hoạt về loại instance, workloads của bạn sẽ tự động chọn phương án tiết kiệm chi phí nhất từ các capacity pools sẵn có. Ngoài ra, bạn có thể sử dụng chiến lược “prioritized” khi muốn kiểm soát nhiều hơn về loại instance nào được chọn trước:\n\u0026ldquo;OnDemandAllocationStrategy\u0026rdquo;: \u0026ldquo;prioritized\u0026rdquo;\nKỹ thuật thích ứng theo vùng (Regional adaptation techniques)\nKhông phải tất cả các AWS Regions đều có sẵn cùng loại Graviton instance. Sự khác biệt về khả năng sẵn có của loại instance giữa các vùng tạo ra thách thức khi triển khai ứng dụng một cách nhất quán trên nhiều AWS Regions. Để xử lý những khác biệt này, hãy mở rộng tính linh hoạt về loại instance vượt quá tối thiểu 10 loại, đảm bảo có đủ tùy chọn trong mỗi AWS Region mà bạn vận hành.\nĐể triển khai tính linh hoạt này trên các AWS Regions, bạn cần xác định loại Graviton instance nào có sẵn ở từng vùng mục tiêu. AWS cung cấp nhiều phương pháp để truy cập thông tin này: kiểm tra tài liệu Amazon EC2 Instance Types by Region để có danh sách đầy đủ, sử dụng DescribeInstanceTypeOfferings Amazon EC2 API để xác định các loại có sẵn theo lập trình, hoặc truy cập trang [EC2 Instance Types page in the AWS Management Console](https://console.aws.amazon.com/ec2/home InstanceTypes:v=3).\nBạn cũng có thể chạy GetInstanceTypesFromInstanceRequirements API trên các AWS Regions khác nhau để hiểu sự khác biệt theo vùng. Ví dụ, chạy các truy vấn giống nhau ở US East (N. Virginia) và Asia Pacific (Taipei) cho thấy sự khác biệt đáng kể: hơn 70 loại instance tương thích ở US East (N. Virginia) và 27 loại ở Asia Pacific (Taipei).\n\\ Query for US East (N. Virginia)\naws ec2 get-instance-types-from-instance-requirements \\\n--architecture-types arm64 \\\n--virtualization-types hvm \\\n--instance-requirements \u0026lsquo;{\u0026ldquo;VCpuCount\u0026rdquo;: {\u0026ldquo;Min\u0026rdquo;: 2,\u0026ldquo;Max\u0026rdquo;:8}, \u0026ldquo;MemoryMiB\u0026rdquo;: {\u0026ldquo;Min\u0026rdquo;: 8000}, \u0026ldquo;InstanceGenerations\u0026rdquo;:[\u0026ldquo;current\u0026rdquo;]}\u0026rsquo; \\\n--region us-east-1\n\\ Query for Asia Pacific (Taipei)\naws ec2 get-instance-types-from-instance-requirements \\\n--architecture-types arm64 \\\n--virtualization-types hvm \\\n--instance-requirements \u0026lsquo;{\u0026ldquo;VCpuCount\u0026rdquo;: {\u0026ldquo;Min\u0026rdquo;: 2,\u0026ldquo;Max\u0026rdquo;:8}, \u0026ldquo;MemoryMiB\u0026rdquo;: {\u0026ldquo;Min\u0026rdquo;: 8000}, \u0026ldquo;InstanceGenerations\u0026rdquo;:[\u0026ldquo;current\u0026rdquo;]}\u0026rsquo; \\\n--region ap-east-2\nKhi vận hành trên nhiều AWS Regions, hãy thiết kế một mixed instance policy duy nhất hoạt động ở tất cả các vùng bằng cách bao gồm các loại instance có sẵn ở tất cả các AWS Regions mà bạn đang hoạt động. Dựa trên kết quả truy vấn trước, bạn có thể bao gồm 10 loại instance sau có sẵn ở cả hai AWS Regions: m6g.large, m7g.large, m6gd.large, m7gd.large, c6g.xlarge, c7g.xlarge, m6g.xlarge, m7g.xlarge, c6gn.xlarge và m6gd.xlarge.\nBạn cũng nên triển khai EC2 Auto Scaling group của mình trên nhiều Availability Zones (AZs) để tăng khả năng chịu lỗi và truy cập vào các capacity pools sâu hơn. Để xác định các AZ có sẵn trong AWS Region của bạn, tham khảo tài liệu Availability Zones hoặc kiểm tra Amazon Virtual Private Cloud (Amazon VPC) để xác định AZ nào đang được các subnet sử dụng thông qua DescribeSubnets Amazon EC2 API. Cấu hình EC2 Auto Scaling group để sử dụng tất cả các AZ có sẵn bằng cách sử dụng tham số [AvailabilityZones](https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-autoscaling-autoscalinggroup.html cfn-autoscaling-autoscalinggroup-availabilityzones) trong CloudFormation AWS::AutoScaling::AutoScalingGroup:\n\u0026ldquo;AvailabilityZones\u0026rdquo;: [\n\u0026ldquo;us-west-2a\u0026rdquo;,\n\u0026ldquo;us-west-2b\u0026rdquo;,\n\u0026ldquo;us-west-2c\u0026rdquo;,\n\u0026ldquo;us-west-2d\u0026rdquo;,\n]\nCác phương pháp hay nhất để sử dụng EC2 Spot Instances với các phiên bản dựa trên Graviton\nMặc dù tối ưu hóa khả năng sẵn có theo vùng và phân bổ AZ cung cấp nền tảng vững chắc, việc nâng cao chiến lược triển khai Graviton với cấu hình Amazon EC2 Spot Instances đúng cách có thể cải thiện đáng kể hiệu quả chi phí mà không làm giảm độ tin cậy. Khi sử dụng Spot Instances với Graviton, bạn nên triển khai các chiến lược tối đa hóa cơ hội có được và duy trì capacity.\nĐầu tiên, Spot Instance Advisor cung cấp thông tin hữu ích về tần suất gián đoạn của các loại instance khác nhau trên các AWS Regions. Sử dụng công cụ này để xác định các loại Graviton instance có tỉ lệ gián đoạn thấp hơn trong các vùng mục tiêu của bạn. Sau đó, mở rộng mixed instance group để bao gồm các loại instance này. Đặc biệt với workload sử dụng Spot Instances, hãy tối đa hóa tính linh hoạt về loại instance bằng cách chỉ định tối đa giới hạn 40 loại instance cho EC2 Auto Scaling groups mixed instance policies. Việc lựa chọn rộng rãi này tăng cơ hội tìm được Spot Instances capacity sẵn có.\nNgoài việc chọn loại instance, chiến lược phân bổ mà bạn chọn ảnh hưởng đáng kể đến khả năng duy trì Spot Instances capacity. Cấu hình chiến lược phân bổ Spot bằng cách sử dụng thuộc tính AWS::AutoScaling::AutoScalingGroup InstancesDistribution với tham số [SpotAllocationStrategy](https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-properties-autoscaling-autoscalinggroup-instancesdistribution.html cfn-autoscaling-autoscalinggroup-instancesdistribution-spotallocationstrategy) đặt là[price-capacity-optimized](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-fleet-allocation-strategy.html ec2-fleet-allocation-strategies-for-spot-instances), để chọn các Spot pools có nguy cơ gián đoạn thấp nhất đồng thời vẫn cân nhắc giá:\n\u0026ldquo;InstancesDistribution\u0026rdquo;: {\n\u0026ldquo;SpotAllocationStrategy\u0026rdquo;: \u0026ldquo;price-capacity-optimized\u0026rdquo;\n}\nĐối với các workload có thể hưởng lợi từ thời gian nhiều hơn so với thông báo gián đoạn Spot chuẩn hai phút, hãy bật Capacity Rebalancing. Tính năng này, được cấu hình thông qua thuộc tính [AWS::AutoScaling::AutoScalingGroup CapacityRebalance](https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-resource-autoscaling-autoscalinggroup.html cfn-autoscaling-autoscalinggroup-capacityrebalance), cho phép EC2 Auto Scaling phản ứng chủ động theo các khuyến nghị rebalancing bằng cách khởi chạy một Spot Instance mới trước khi instance đang chạy nhận thông báo gián đoạn Spot hai phút, từ đó cung cấp thêm thời gian để thực hiện chuyển đổi một cách mượt mà:\n\u0026ldquo;CapacityRebalance\u0026rdquo;: true\nĐể đạt tính linh hoạt tối đa và truy cập capacity tốt hơn, hãy xem xét việc kết hợp cả kiến trúc x86 và ARM trong launch templates. Mặc dù các Graviton capacity pools mới hơn và đôi khi nhỏ hơn so với x86, cách tiếp cận kiến trúc hỗn hợp đảm bảo bạn vẫn có thể khởi chạy instance ngay cả khi một kiến trúc có sẵn hạn chế. Để hướng dẫn chi tiết, tham khảo bài viết AWS:Supporting AWS Graviton2 and x86 instance types in the same Auto Scaling group.\nLựa chọn loại instance dựa trên thuộc tính (Attribute-based instance type selection)\nMặc dù mixed instance policies với danh sách loại instance cụ thể cung cấp sự linh hoạt tuyệt vời, AWS còn cung cấp một phương pháp mạnh mẽ hơn cho việc lựa chọn động loại instance: attribute-based instance type selection. Phương pháp này giúp quản lý dễ dàng hơn bằng cách cho phép bạn chỉ định các thuộc tính mà ứng dụng cần thay vì loại instance cụ thể, tự động thích ứng với các loại instance mới và xử lý sự khác biệt về sẵn có theo vùng.\nBạn có thể triển khai lựa chọn loại instance dựa trên thuộc tính trong EC2 Launch Template thông qua thuộc tính AWS::EC2::LaunchTemplate InstanceRequirements:\n{\n\u0026ldquo;InstanceRequirements\u0026rdquo;: {\n\u0026quot;AcceleratorCount\u0026quot;: { \u0026quot;Max\u0026quot;: 0 }, \u0026quot;BareMetal\u0026quot;: \u0026quot;excluded\u0026quot;, \u0026quot;BaselinePerformanceFactors\u0026quot;: { \u0026quot;Cpu\u0026quot;: { \u0026quot;References\u0026quot;: \\[ { \u0026quot;InstanceFamily\u0026quot;: \u0026quot;c7g\u0026quot; } \\] } }, \u0026quot;InstanceGenerations\u0026quot;: \\[ \u0026quot;current\u0026quot; \\], \u0026quot;MemoryMiB\u0026quot;: { \u0026quot;Min\u0026quot;: 8000 }, \u0026quot;VCpuCount\u0026quot;: { \u0026quot;Min\u0026quot;: 4 } }\n}\nBaselinePerformanceFactors trong AWS::EC2::LaunchTemplate InstanceRequirements đảm bảo [performance protection](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-fleet-attribute-based-instance-type-selection.html ec2fleet-abis-performance-protection). Tính năng này đảm bảo EC2 Auto Scaling group sử dụng các loại instance đạt hoặc vượt mức hiệu suất cơ bản đã định. Khi bạn chỉ định một instance family như “c7g” làm tham chiếu cơ sở, Amazon EC2 sẽ tự động loại trừ các loại instance dưới mức hiệu suất này, ngay cả khi chúng phù hợp với các thuộc tính khác đã chỉ định. Với triển khai Graviton, việc chỉ định “c7g” đảm bảo chỉ chọn các loại instance có hiệu suất tương đương hoặc tốt hơn Graviton3 processors.\nLựa chọn loại instance dựa trên thuộc tính cũng cho phép chỉ định các loại instance trong template mà có thể chưa có sẵn trong một AWS Region bằng cách sử dụng [AllowedInstanceTypes](https://docs.aws.amazon.com/AWSCloudFormation/latest/TemplateReference/aws-properties-ec2-launchtemplate-instancerequirements.html cfn-ec2-launchtemplate-instancerequirements-allowedinstancetypes):\n{\n\u0026ldquo;AllowedInstanceTypes\u0026rdquo;: [\n\u0026quot;m6g.large\u0026quot;, \u0026quot;m7g.large\u0026quot;, \u0026quot;m8g.large\u0026quot; ]\n}\nCách tiếp cận này giúp EC2 Auto Scaling group sử dụng các loại instance mới khi có sẵn và triển khai tự động ở các AWS Regions khác khi chúng trở nên khả dụng. Template duy nhất này đơn giản hóa việc triển khai và quản lý lựa chọn instance trong EC2 Auto Scaling groups trên nhiều vùng.\nCác lưu ý đặc biệt\nNhững cân nhắc đặc biệt sau đây cần được lưu ý.\nKiểm thử hiệu suất với nhiều loại instance\nKhi triển khai linh hoạt loại instance, một mối quan tâm phổ biến là cần kiểm thử tất cả các loại instance với ứng dụng. Việc thử nghiệm 40 loại instance khác nhau là không thực tế đối với hầu hết tổ chức. Thay vào đó, hãy cân nhắc các cách tiếp cận sau để giảm khối lượng kiểm thử mà vẫn đảm bảo hiệu suất:\nCác Graviton instance families trong cùng thế hệ (ví dụ: c7g, m7g, r7g) sử dụng cùng một processor, cung cấp hiệu suất tương tự. Do đó, bạn có thể bao gồm nhiều loại instance từ cùng thế hệ sau khi kiểm thử một instance đại diện.\nCân nhắc bao gồm các biến thể trong family (ví dụ: c7gd với NVMe storage), vì chúng cung cấp khả năng chuyên biệt mà không thay đổi kiến trúc CPU cơ bản.\nĐể đạt tính linh hoạt tối đa, hãy bao gồm nhiều thế hệ instance.\nNếu ứng dụng chạy tốt trên Graviton3, thì rất có thể sẽ chạy tốt hơn trên Graviton4, cho phép bạn chỉ định cả hai trong EC2 Auto Scaling group.\nĐặt trước loại Graviton cụ thể\nNếu workload cần một loại Graviton instance cụ thể, hãy sử dụng EC2 Capacity Reservations, cho phép đặt trước capacity cho EC2 instance trong một AZ cụ thể trong bất kỳ khoảng thời gian nào.\nOn-Demand Capacity Reservations (ODCR) dành cho sử dụng ngay và không yêu cầu cam kết thời hạn.\nFuture-dated Capacity Reservations cho phép chỉ định thời điểm capacity cần sẵn có cùng với thời gian cam kết.\nAmazon EMR workloads\nMặc dù các Amazon EMR clusters chỉ tồn tại trong một AZ, bạn có thể sử dụng Amazon EMR instance fleets để chọn nhiều subnet qua các AZ khác nhau. Khi khởi tạo cluster, Amazon EMR tìm kiếm qua các subnet này để tìm instance và phương thức mua cụ thể, từ đó truy cập vào capacity pool sâu hơn. Với Instance Fleets, bạn có thể chỉ định tới 30 loại EC2 instance cho mỗi nhóm node primary, core, và task, cải thiện đáng kể tính linh hoạt và khả năng sẵn có của instance. Tham khảo thêm: Responding to Amazon EMR cluster insufficient instance capacity events.\nKết luận\nBài viết này trình bày các chiến lược nâng cao để tối đa hóa việc áp dụng AWS Graviton trên nhiều AWS Regions. Bạn có thể sử dụng các ví dụ AWS CloudFormation được cung cấp như template cho triển khai của riêng mình. Theo các phương pháp này giúp duy trì hiệu suất ứng dụng nhất quán và tối đa hóa khả năng sẵn có của Graviton instance trên tất cả các AWS Regions mà bạn vận hành, ngay cả khi khả năng sẵn có của Graviton tiếp tục mở rộng trên hạ tầng toàn cầu của AWS. Để có hướng dẫn toàn diện về tối đa hóa triển khai Graviton, hãy tham khảo AWS Graviton Technical Guide.\nNguồn:https://aws.amazon.com/vi/blogs/compute/implementing-advanced-aws-graviton-adoption-strategies-across-aws-regions/\n"
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.3-week3/",
	"title": "Tuần 3 - Dịch vụ Compute trên AWS",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-09-22 đến 2025-09-26\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 3 Tuần này tập trung vào các dịch vụ Compute của AWS, đặc biệt là Amazon EC2 và những dịch vụ bổ trợ.\nNội dung chính Amazon EC2 và các loại instance. AMI và chiến lược sao lưu. EBS và Instance Store. EC2 Auto Scaling. Lựa chọn mô hình giá cho EC2. Amazon Lightsail, EFS, FSx. Labs thực hành Lab 01: AWS Account \u0026amp; IAM Setup. Lab 07: AWS Budgets \u0026amp; Cost Management. Lab 09: AWS Support Plans. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.4-api-gateway/",
	"title": "API Gateway",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Xuất bản Lambda qua API Gateway (REST), tạo resource/method, và kiểm thử GET/POST bằng curl hoặc Postman.\nCác bước Tạo REST API, resource /hello, bật CORS nếu cần. Thêm method GET/POST, map tới Lambda (proxy integration). Deploy stage dev, ghi lại Invoke URL. Kiểm thử GET/POST, xử lý lỗi (400) khi thiếu dữ liệu. Tùy chọn bật CORS hoặc custom domain. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/4-eventparticipated/",
	"title": "Các Sự Kiện Tham Gia",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập, tôi đã có cơ hội tham gia vào nhiều sự kiện có tác động lớn, giúp làm phong phú thêm hành trình chuyên nghiệp của tôi với những kiến thức quý báu và những trải nghiệm đáng nhớ.\nSự Kiện 1 Tên Sự Kiện: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nNgày \u0026amp; Giờ: 09:00 – 17:00 VNT, Thứ Năm, 18 tháng 9 năm 2025\nĐịa Điểm: Tầng 36, 2 Đường Hai Triều, Phường Sài Gòn, Thành phố Hồ Chí Minh\nVai Trò: Người tham dự\nMô Tả: Vietnam Cloud Day 2025 là một sự kiện AWS toàn diện với các bài phát biểu chính từ các nhà lãnh đạo chính phủ, các giám đốc điều hành AWS và các lãnh đạo ngành. Sự kiện bao gồm hai track chính: track phát sóng trực tiếp với các bài phát biểu chính và thảo luận bảng về cuộc cách mạng GenAI và lãnh đạo cấp cao, cùng các track riêng biệt bao gồm các chủ đề như nền tảng dữ liệu thống nhất cho AI/phân tích, lộ trình áp dụng GenAI, vòng đời phát triển do AI điều khiển, bảo mật các ứng dụng GenAI và các tác nhân AI để tăng năng suất. Sự kiện này giới thiệu các dịch vụ mới nhất của AWS và các sáng kiến chiến lược cho AI và hiện đại hóa đám mây.\nKết Quả: Hiểu rõ hơn về các chiến lược áp dụng AI ở quy mô doanh nghiệp, tìm hiểu về các dịch vụ AWS cho nền tảng dữ liệu và triển khai GenAI, và nắm vững các thực tiễn tốt nhất để bảo mật các ứng dụng AI và hiện đại hóa các hệ thống cũ.\nSự Kiện 2 Tên Sự Kiện: AWS GenAI Builder Club - AI-Driven Development Life Cycle: Reimagining Software Engineering\nNgày \u0026amp; Giờ: 14:00 (2:00 PM), Thứ Sáu, 3 tháng 10 năm 2025\nĐịa Điểm: AWS Event Hall, L26 Tòa Nhà Bitexco, Thành phố Hồ Chí Minh\nVai Trò: Người tham dự\nMô Tả: Phiên làm việc AWS GenAI Builder Club này tập trung vào Vòng Đời Phát Triển Do AI Điều Khiển (AI-DLC), khám phá cách AI tạo sinh biến đổi phát triển phần mềm từ kiến trúc đến triển khai và bảo trì. Phiên làm việc này có các bản trình diễn về Amazon Q Developer và Kiro, cho thấy cách AI có thể tự động hóa các tác vụ nặng nề không phân biệt và cho phép các nhà phát triển tập trung vào công việc sáng tạo có giá trị cao hơn. Chương trình bao gồm tổng quan về các khái niệm AI-DLC, khả năng của Amazon Q Developer và các bản trình diễn Kiro thực hành.\nKết Quả: Học được các ứng dụng thực tế của AI trong vòng đời phát triển phần mềm, có được kinh nghiệm thực hành với các công cụ Amazon Q Developer và Kiro, và hiểu cách tích hợp AI như một cộng tác viên trung tâm trong các quy trình phát triển để tăng năng suất và chất lượng mã.\n"
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.4-api-gateway/5.4.4-cors-custom-domain/",
	"title": "CORS &amp; custom domain",
	"tags": [],
	"description": "",
	"content": "Bật CORS Chọn method → Enable CORS → thêm header Content-Type và phương thức cần thiết. Deploy lại stage sau khi bật. Custom domain (tùy chọn) API Gateway → Custom domain names → tạo domain và map stage dev → /. Cập nhật DNS CNAME trỏ về domain API Gateway. Kiểm thử lại Gọi GET/POST qua domain mới hoặc với header CORS phù hợp. Nếu browser báo CORS, kiểm tra lại cấu hình CORS và Deploy. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.4-week4/",
	"title": "Tuần 4 - Dịch vụ Lưu trữ trên AWS",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-09-29 đến 2025-10-03\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 4 Tuần này tập trung vào các dịch vụ lưu trữ của AWS, từ S3 cho tới giải pháp hybrid và chiến lược DR.\nNội dung chính Amazon S3 và các lớp lưu trữ. S3 Static Website Hosting. S3 Glacier cho lưu trữ dài hạn. AWS Snow Family. AWS Storage Gateway. Chiến lược Disaster Recovery. AWS Backup. Labs thực hành Lab 13: AWS Backup. Lab 14: AWS VM Import/Export. Lab 24: AWS Storage Gateway. Lab 25: Amazon FSx. Lab 57: Amazon S3 \u0026amp; CloudFront. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.5-week5/",
	"title": "Tuần 5 - Bảo mật &amp; Danh tính trên AWS",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-10-06 đến 2025-10-10\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 5 Tuần này tập trung vào bảo mật và quản lý danh tính trên AWS.\nNội dung chính Mô hình Trách nhiệm chia sẻ. AWS IAM (Users, Groups, Roles, Policies). Amazon Cognito. AWS Organizations \u0026amp; SCPs. AWS Identity Center (SSO). AWS KMS. AWS Security Hub. Labs thực hành Lab 18: AWS Security Hub. Lab 22: AWS Lambda Automation with Slack. Lab 27: AWS Resource Groups \u0026amp; Tagging. Lab 28: IAM Cross-Region Role \u0026amp; Policy. Lab 30: IAM Restriction Policy. Lab 33: AWS KMS \u0026amp; CloudTrail Integration. Lab 44: IAM Advanced Role Control. Lab 48: IAM Access Keys \u0026amp; Roles. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.5-sample-app/",
	"title": "Ứng dụng mẫu: Gợi ý in-app purchase",
	"tags": [],
	"description": "",
	"content": "Bài tập: Gợi ý in-app purchase Xây dựng hàm Lambda nhận danh sách item đã mua và trả về gợi ý các item chưa mua (phép trừ tập hợp đơn giản).\nYêu cầu đầu vào { \u0026#34;allItems\u0026#34;: [\u0026#34;starter_pack\u0026#34;,\u0026#34;booster_pack\u0026#34;,\u0026#34;data_pack\u0026#34;,\u0026#34;golden_apples\u0026#34;,\u0026#34;skins\u0026#34;], \u0026#34;owned\u0026#34;: [\u0026#34;data_pack\u0026#34;,\u0026#34;starter_pack\u0026#34;] } Xử lý Dùng tập hợp để lấy phần còn lại: suggestions = allItems - owned. Trả JSON { \u0026quot;suggestions\u0026quot;: [...] } và mã 200. Log input/output để dễ debug. Kiểm thử Trong console: tạo test event với nhiều giá trị owned. Qua API Gateway: POST /suggest body JSON như trên. Thử lỗi: thiếu allItems hoặc owned → trả 400 với thông báo rõ ràng. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Workshop Tổng quan Workshop serverless với AWS Lambda và API Gateway: tạo hàm Hello World (Node.js/Python), thêm tham số, xuất bản API GET/POST, và xây dựng hàm gợi ý in-app purchase. Tập trung triển khai nhanh, không quản lý server, chú ý chi phí và vận hành.\nNội dung Giới thiệu Chuẩn bị Lambda cơ bản API Gateway Hàm gợi ý (sample app) Dọn dẹp "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.6-week6/",
	"title": "Tuần 6 - AWS Database Services",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-10-13 đến 2025-10-17\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 6 Tuần này tập trung vào hệ sinh thái cơ sở dữ liệu trên AWS: từ dịch vụ quan hệ managed, NoSQL chuyên dụng, bộ nhớ đệm in-memory cho tới data warehouse phân tích.\nNội dung chính Database Fundamentals (RDBMS, NoSQL, OLTP vs OLAP) Amazon RDS \u0026amp; Aurora Amazon Redshift Amazon ElastiCache AWS Database Migration Service (DMS) Labs thực hành Lab 05: Amazon RDS \u0026amp; EC2 Integration Lab 43: AWS Database Migration Service (DMS) "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại First Cloud Journey (FCJ) - AWS từ ngày 8 tháng 9 năm 2025 đến ngày 28 tháng 11 năm 2025 (12 tuần), tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia nhiều trình độ học tập AWS và các dự án thực hành, qua đó cải thiện kỹ năng thiết kế kiến trúc đám mây, triển khai dịch vụ AWS, lập tài liệu kỹ thuật, dịch blog và phát triển hội thảo.\nCác thành tựu chính Trong suốt thời gian thực tập, tôi đã hoàn thành những công việc chính sau:\nHành trình học tập AWS (12 tuần): Nghiên cứu có hệ thống các dịch vụ AWS cơ bản bao gồm EC2, S3, RDS, Lambda, API Gateway, VPC, IAM, CloudWatch và các phương pháp hay nhất về bảo mật.\nĐề xuất thách thức: Phát triển các đề xuất toàn diện cho các thách thức và giải pháp cơ sở hạ tầng đám mây.\nDịch blog: Dịch 3+ bài đăng blog AWS kỹ thuật từ tiếng Anh sang tiếng Việt, bao gồm các chủ đề như Amazon SageMaker, phiên bản EC2 Mac và hướng dẫn tối ưu hóa AMD.\nPhát triển hội thảo: Tạo hội thảo thực hành về tích hợp dịch vụ AWS với các ví dụ thực tế và hướng dẫn từng bước cho các phòng thí nghiệm thực hành.\nTham dự sự kiện: Tham dự 2 sự kiện AWS chính:\nVietnam Cloud Day 2025 (ngày 18 tháng 9 năm 2025) AWS GenAI Builder Club - AI-Driven Development Life Cycle (ngày 3 tháng 10 năm 2025) Về tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc X 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh X 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn X 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng X 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc X 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân X 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng X 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm X 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc X 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo X 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team X 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập X Những điểm mạnh Nền tảng kỹ thuật vững chắc: Đã học tập và áp dụng thành công nhiều dịch vụ AWS trên các lĩnh vực tính toán, lưu trữ, mạng, cơ sở dữ liệu và bảo mật. Kỹ năng lập tài liệu: Sản xuất tài liệu kỹ thuật chất lượng cao bao gồm các đề xuất, blog dịch và tài liệu hội thảo. Hợp tác nhóm: Tích cực tham gia các hoạt động nhóm và sự kiện AWS, kết nối với các thành viên FCJ và chuyên gia trong ngành. Khả năng tự học: Thể hiện khả năng nghiên cứu độc lập các khái niệm đám mây phức tạp và thực hiện các phòng thí nghiệm thực hành. Cần cải thiện Nâng cao tính kỷ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ tổ chức nào Cải thiện cách tư duy giải quyết vấn đề và tiếp cận các thách thức một cách có hệ thống Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống hiệu quả Quản lý thời gian tốt hơn để tuân thủ các thời hạn một cách nhất quán "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.7-week7/",
	"title": "Tuần 7 - Vertical Slice Delivery",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-10-20 đến 2025-10-24\nTrạng thái: \u0026ldquo;Hoàn thành\u0026rdquo;\nTổng quan tuần 7 Tuần này hoàn thiện vertical slice 0 cho dự án Ebook Demo, tập trung vào contract-first development và tự động hóa kiểm thử để có thể demo end-to-end sớm.\nNội dung chính Vertical Slice Architecture \u0026amp; phạm vi slice 0 Contract-first development với OpenAPI + Prism mock Next.js 16 App Router \u0026amp; Server Components FastAPI clean architecture và cấu hình CORS Schemathesis contract testing \u0026amp; retrospective Labs thực hành Checklist demo vertical slice 0 Mock API bằng Prism và kết nối Next.js Refactor backend FastAPI theo clean architecture Chạy Schemathesis và cập nhật workflow chuẩn "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Bùi Văn Vũ\nSố điện thoại: 0353380809\nEmail: vubui.cv2021@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Công nghệ thông tin\nId: SE180080\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 8/09/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.8-week8/",
	"title": "Tuần 8 - Xử Lý Ngôn Ngữ Tự Nhiên &amp; Deep Learning",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-10-27 to 2025-10-31\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nTổng Quan Tuần 8 Tuần này cung cấp cái nhìn sâu rộng về Xử Lý Ngôn Ngữ Tự Nhiên (NLP), bao gồm nền tảng ngôn ngữ học, ứng dụng NLP hiện đại, kiến trúc sequence-to-sequence, và phương pháp đánh giá. Từ hiểu biết về âm vị học đến triển khai hệ thống dịch máy, tuần này kết nối lý thuyết và thực hành trong NLP.\nCác Chủ Đề Chính Nền Tảng Ngôn Ngữ Học Các thành phần cốt lõi: Âm Vị Học, Âm Vị Học, Hình Thái Học, Cú Pháp, Ngữ Nghĩa, Thực Dụng Hiểu cấu trúc ngôn ngữ ảnh hưởng đến thiết kế NLP như thế nào Ứng Dụng NLP Công cụ tìm kiếm và nhận dạng ý định Quảng cáo trực tuyến với NER và trích xuất mối quan hệ Trợ lý giọng nói và nhận dạng giọng nói Chatbot với pipeline NLU/NLG Hệ thống dịch máy Tóm tắt văn bản (extractive \u0026amp; abstractive) Kiến Trúc Deep Learning Mô hình Seq2seq với kiến trúc encoder-decoder LSTM chi tiết: forget gate, input gate, cell state, output gate Cơ chế Attention và self-attention Triển khai Neural Machine Translation (NMT) Đánh Giá \u0026amp; Decoding Điểm BLEU (dựa trên precision) Điểm ROUGE (dựa trên recall) Điểm F1 để đánh giá MT Beam search decoding Minimum Bayes Risk (MBR) sampling Phòng Thí Nghiệm Thực Hành Xây dựng workflow voicebot và chatbot Triển khai LSTM cho sequence modeling Tạo encoder-decoder với attention Neural machine translation end-to-end Đánh giá chất lượng dịch với BLEU/ROUGE Triển khai beam search và MBR "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.9-week9/",
	"title": "Tuần 9 - Kiến Trúc &amp; Triển Khai Transformer",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-11-03 to 2025-11-07\nTrạng Thái: \u0026ldquo;Hoàn Thành\u0026rdquo;\nTóm Tắt Tuần 9 Tuần này khám phá kiến trúc Transformer, một mô hình cách mạng thay thế RNNs trong NLP. Chúng ta sẽ hiểu tại sao cần transformers, cách chúng hoạt động bên trong, và triển khai chúng từ đầu. Từ các cơ chế attention đến thiết kế encoder-decoder đầy đủ, tuần này kết nối lý thuyết và triển khai thực tế.\nCác Chủ Đề Chính Hạn Chế của RNNs \u0026amp; Giới Thiệu Transformer Thắt cổ chai xử lý tuần tự trong RNNs Vấn đề Vanishing Gradient Thắt cổ chai thông tin với chuỗi dài Tại sao Attention là tất cả bạn cần Kiến Trúc Transformer Cấu trúc Encoder-Decoder Lớp Multi-head Attention Positional Encoding Residual Connections \u0026amp; Layer Normalization Feed-forward Networks Cơ Chế Attention Scale Dot-product Attention (cơ chế lõi) Self-attention (cùng một câu) Masked Attention (Decoder) Encoder-Decoder Attention Multi-head Attention để tính toán song song Transformer Decoder \u0026amp; GPT2 Positional Embeddings Decoder Block Implementation Feed-forward Layer Design Tính toán Xác suất Output Ứng Dụng \u0026amp; Các Mô Hình GPT-2 (Generative Pre-trained Transformer) BERT (Bidirectional Encoder Representations) T5 (Text-to-Text Transfer Transformer) Ứng dụng: Dịch, Phân loại, QA, Tóm tắt, Phân tích Cảm xúc Mục Tiêu Học Tập ✅ Hiểu hạn chế của RNN và tại sao transformers giải quyết chúng ✅ Nắm bắt kiến trúc transformer hoàn chỉnh ✅ Triển khai các cơ chế attention từ đầu ✅ Xây dựng transformer decoder (kiểu GPT2) ✅ Nhận biết các ứng dụng transformer và các mô hình tiên tiến Chia Nhỏ Theo Ngày Ngày Tập Trung Chủ Đề 41 Vấn Đề RNN Xử lý tuần tự, Vanishing Gradients, Thắt cổ chai thông tin 42 Tổng Quan Kiến Trúc Encoder-Decoder, Multi-head Attention, Positional Encoding 43 Lõi Attention Công thức Scale Dot-product, Phép toán ma trận, Hiệu quả GPU 44 Các Loại Attention Self-attention, Masked Attention, Encoder-Decoder Attention 45 Triển Khai Decoder Kiến trúc GPT2, Các khối xây dựng, Hướng dẫn Code Điều Kiện Tiên Quyết Hiểu biết sâu về RNNs, LSTMs, và attention từ Tuần 8 Thoải mái với phép toán ma trận và đại số tuyến tính Kiến thức PyTorch hoặc TensorFlow rất hữu ích Các Bước Tiếp Theo Học bài báo \u0026ldquo;Attention is All You Need\u0026rdquo; (Vaswani et al., 2017) Triển khai các thành phần transformer từng bước Thử nghiệm với các mô hình được huấn luyện trước (BERT, GPT-2, T5) "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.10-week10/",
	"title": "Tuần 10 - Transfer Learning, BERT &amp; T5",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-11-10 đến 2025-11-14\nTrạng thái: \u0026ldquo;Đang thực hiện\u0026rdquo;\nTổng quan Tuần 10 Tuần này tập trung vào transfer learning cho NLP và cách QA hiện đại tận dụng transformer tiền huấn luyện. Ta so sánh huấn luyện truyền thống với reuse đặc trưng và fine-tuning, rồi đi vào hai mô hình tiêu biểu: BERT (ngữ cảnh hai chiều) và T5 (text-to-text đa nhiệm), kèm cách thiết lập QA có ngữ cảnh vs. closed-book.\nChủ đề chính Nền tảng Transfer Learning Pipeline truyền thống vs. pipeline transfer Tái dùng trọng số tiền huấn luyện để hội tụ nhanh hơn So sánh feature-based với fine-tuning Lợi ích: nhanh hơn, chính xác hơn, ít dữ liệu nhãn Hai chế độ Question Answering QA có ngữ cảnh (trích span/sinh ngắn dựa vào đoạn văn) QA closed-book (sinh câu trả lời không có context) Ảnh hưởng của chất lượng tiền huấn luyện lên QA BERT và ngữ cảnh hai chiều Masked Language Modeling cho embedding ngữ cảnh Next Sentence Prediction cho coherence mức câu Dùng cả trái và phải để dự đoán token Ứng dụng: QA, sentiment, phân loại T5 đa nhiệm text-to-text Định dạng text-to-text cho nhiều tác vụ Prompt chung cho rating, QA, tóm tắt, dịch Mở rộng dữ liệu (C4 so với Wikipedia) Chuyển giao đa nhiệm để tổng quát hóa tốt hơn Chiến lược dữ liệu \u0026amp; huấn luyện Pha trộn dữ liệu có nhãn/không nhãn; self-supervised masking Đóng băng backbone vs. thêm head Công thức fine-tuning cho QA/tóm tắt/dịch Mục tiêu học tập Giải thích khi nào nên dùng transfer thay vì huấn luyện từ đầu Phân biệt reuse đặc trưng và fine-tuning toàn bộ So sánh QA có ngữ cảnh và QA closed-book Tóm lược cách BERT và T5 tiền huấn luyện và chuyển giao Nêu vì sao transfer giúp giảm dữ liệu nhãn và thời gian train Lịch trong tuần Ngày Trọng tâm Chủ đề 46 Giới thiệu Transfer Pipeline truyền thống vs. transfer, reuse trọng số, feature-based vs. fine-tuning, lợi ích 47 Question Answering QA có ngữ cảnh vs. closed-book, nhu cầu dữ liệu, cách đánh giá 48 BERT hai chiều Masked LM, NSP, tận dụng ngữ cảnh hai phía cho dự đoán token 49 Mô hình T5 Prompt text-to-text, chia sẻ đa nhiệm, mở rộng dữ liệu (C4 vs. Wikipedia) 50 Thực hành fine-tuning Đóng băng/lộ trình unfreeze, downstream: QA, tóm tắt, dịch Yêu cầu nền tảng Nắm vững kiến trúc transformer từ Tuần 9 Thoải mái với attention và luồng encoder-decoder Cơ bản PyTorch/TensorFlow để fine-tune Bước tiếp theo Đọc paper BERT và T5 để hiểu mục tiêu pre-train Fine-tune thử model BERT QA (kiểu SQuAD span) Thử prompt T5 cho QA, tóm tắt, sentiment So sánh hiệu năng feature-based vs. fine-tune trên dữ liệu của bạn "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.11-week11/",
	"title": "Tuần 11 - Lambda Managed Instances &amp; ghi chú re:Invent",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-11-17 đến 2025-11-21\nTrạng thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nTổng quan Tuần 11 Tóm tắt session AWS re:Invent 2025 (CNS382) về Lambda Managed Instances (LMI): chạy hàm Lambda trên EC2 do Lambda quản lý, giữ nguyên trải nghiệm serverless nhưng chọn được loại máy, giá EC2, và loại bỏ cold start. Trọng tâm: khi nào chọn LMI vs. Lambda mặc định, cách cấu hình capacity provider, và lưu ý test/ops cho workload lưu lượng ổn định.\nChủ đề chính Vì sao LMI Giữ trải nghiệm Lambda nhưng tự chọn họ máy EC2 và tận dụng Savings Plan/Reserved Instance Không cold start, hỗ trợ multi-concurrency trên instance Dễ dự báo chi phí với traffic ổn định Kiến trúc \u0026amp; Thiết lập Capacity Provider: cấu hình VPC, loại máy (C/M/R, x86/Graviton), guardrail scaling Quy trình: tạo capacity provider -\u0026gt; tạo function gắn provider -\u0026gt; publish version để khởi tạo instance Vòng đời do Lambda quản lý: patch OS/runtime, routing/auto scaling; thấy instance nhưng không can thiệp được Mạng \u0026amp; Bảo mật Toàn bộ egress đi qua ENI của instance trong VPC provider; không cấu hình VPC ở mức function Đóng inbound SG; đảm bảo đường ra tới dependency/CloudWatch (Internet hoặc PrivateLink) Mặc định mã hóa EBS, có thể dùng KMS của bạn Tính năng hàm \u0026amp; Scaling Hỗ trợ ZIP/OCI; runtime Java/Python/Node/.NET; layers, extensions, function URL, response streaming, durable functions Memory/CPU quyết định chọn instance; có thể giới hạn/loại trừ loại máy Guardrail scaling ở mức instance (vd max vCPU) để kiểm soát chi phí Phù hợp \u0026amp; Đánh đổi Dùng LMI cho workload lưu lượng cao, ổn định, hoặc cần compute/memory/network đặc thù Giữ Lambda mặc định cho traffic đột biến, ngắn Multi-concurrency + billing kiểu EC2 thay đổi bức tranh cost/perf Mục tiêu học tập Nêu khi nào chọn LMI thay vì Lambda mặc định Cấu hình capacity provider (VPC, role, loại máy, guardrail) Mô tả mô hình mạng và đường log của LMI Ghép tính năng Lambda (đóng gói, runtime, URL, streaming, durable) với LMI Đặt giới hạn scale/chi phí và chọn họ máy phù hợp workload Lịch trong tuần Ngày Trọng tâm Chủ đề 51 Tổng quan \u0026amp; use case Lợi ích LMI, tận dụng giá EC2, khi nào không dùng 52 Capacity Provider VPC, IAM operator role, shortlist loại máy, KMS, guardrail 53 Hàm trên LMI Đóng gói/runtime, ánh xạ memory/CPU, multi-concurrency, publish version 54 Mạng \u0026amp; quan sát Đường egress, CloudWatch, SG, logging, monitoring 55 Scaling \u0026amp; vận hành Max vCPU, kế hoạch traffic ổn định, kiểm soát chi phí, checklist rollout Yêu cầu nền tảng Nắm trải nghiệm Lambda và transformer từ tuần trước Kiến thức cơ bản EC2/VPC, IAM, CloudWatch Hiểu Savings Plan/Reserved Instance cho EC2 Bước tiếp theo Phác capacity provider cho workload mục tiêu (VPC, shortlist instance, guardrail) Lập kế hoạch benchmark LMI vs. Lambda mặc định theo traffic mẫu Vẽ đường giám sát/log (CloudWatch endpoint, PrivateLink nếu cần) Quyết định dùng SP/RI và mục tiêu multi-concurrency cho từng hàm "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/1-worklog/1.12-week12/",
	"title": "Tuần 12 - Thông báo AWS re:Invent 2025",
	"tags": [],
	"description": "",
	"content": "Tuần: 2025-11-24 đến 2025-11-28\nTrạng thái: \u0026ldquo;Kế hoạch\u0026rdquo;\nTổng quan Tuần 12 Tóm tắt re:Invent 2025: dòng Nova mới (speech-to-speech, đa phương thức, reasoning giá rẻ), Bedrock mở rộng (model open-weight, reinforcement fine-tuning), vector/AI hạ tầng (S3 Vectors GA), và phần cứng compute mới như Graviton5, Trainium3 UltraServers. Trọng tâm là lập kế hoạch áp dụng thực tế.\nChủ đề chính GenAI \u0026amp; Model Nova 2: Sonic (speech-to-speech), Lite (nhanh/rẻ), Omni (đa phương thức), Forge để huấn luyện frontier model tùy biến Nova Act cho agent UI ổn định; Bedrock AgentCore thêm policy/quality cho agent Bedrock bổ sung model open-weight (Mistral Large 3, Ministral 3) và reinforcement fine-tuning Vector \u0026amp; Dữ liệu Amazon S3 Vectors GA: tới 2B vector/index, ~100ms truy vấn, chi phí thấp hơn DB chuyên dụng Clean Rooms sinh dữ liệu tổng hợp bảo vệ riêng tư cho ML cộng tác Nền tảng AI Dev SageMaker AI với serverless MLflow; training checkpointless và elastic trên HyperPod Compute \u0026amp; Hardware Graviton5 CPU giá/hiệu năng tốt hơn trên EC2 Trainium3 UltraServers (3nm) cho train/inference nhanh và rẻ hơn Mục tiêu học tập Xác định launch AI/compute nào tác động tới workload hiện tại Lên pilot cho Nova và tính năng Bedrock mới Phác lộ trình chuyển sang S3 Vectors cho lưu trữ/search vector Đánh giá phù hợp Graviton5/Trainium3 cho mục tiêu cost/perf Lịch trong tuần Ngày Trọng tâm Chủ đề 56 Model mới Nova 2 (Sonic, Lite, Omni), Forge, Nova Act 57 Bedrock \u0026amp; Agent Model open-weight, reinforcement fine-tuning, AgentCore policy/quality 58 Vector \u0026amp; dữ liệu S3 Vectors GA, Clean Rooms synthetic, kế hoạch scale/chi phí 59 SageMaker Serverless MLflow, checkpointless \u0026amp; elastic training trên HyperPod 60 Compute mới Graviton5, Trainium3 UltraServers, checklist fit/migration Yêu cầu nền tảng Hiểu catalog Bedrock và khả năng agent Nắm kiến trúc vector search cơ bản Biết các họ EC2 và lựa chọn accelerator Bước tiếp theo Chọn 1 pilot cho Nova (speech/đa phương thức/reasoning) và lập kế hoạch đánh giá Lập POC chuyển sang S3 Vectors so với vector store hiện tại Đặt mục tiêu benchmark cho Graviton5/Trainium3 so với máy đang dùng Xác định yêu cầu governance/policy trước khi dùng AgentCore và Nova Act "
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/hugo_aws/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]